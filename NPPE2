{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201c837b",
   "metadata": {
    "papermill": {
     "duration": 0.007062,
     "end_time": "2025-12-14T07:50:09.597106",
     "exception": false,
     "start_time": "2025-12-14T07:50:09.590044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf47a59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:09.611554Z",
     "iopub.status.busy": "2025-12-14T07:50:09.611319Z",
     "iopub.status.idle": "2025-12-14T07:50:48.690880Z",
     "shell.execute_reply": "2025-12-14T07:50:48.689825Z"
    },
    "papermill": {
     "duration": 39.095991,
     "end_time": "2025-12-14T07:50:48.699913",
     "exception": false,
     "start_time": "2025-12-14T07:50:09.603922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trackio -qqq > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa8ac1f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:48.715322Z",
     "iopub.status.busy": "2025-12-14T07:50:48.715049Z",
     "iopub.status.idle": "2025-12-14T07:50:58.509708Z",
     "shell.execute_reply": "2025-12-14T07:50:58.508804Z"
    },
    "papermill": {
     "duration": 9.804353,
     "end_time": "2025-12-14T07:50:58.511531",
     "exception": false,
     "start_time": "2025-12-14T07:50:48.707178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Imports Done, Good to go....\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trackio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import subprocess\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import kagglehub\n",
    "\n",
    "print(\"All Imports Done, Good to go....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8a9348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:58.528176Z",
     "iopub.status.busy": "2025-12-14T07:50:58.527606Z",
     "iopub.status.idle": "2025-12-14T07:50:59.232536Z",
     "shell.execute_reply": "2025-12-14T07:50:59.231683Z"
    },
    "papermill": {
     "duration": 0.714453,
     "end_time": "2025-12-14T07:50:59.234297",
     "exception": false,
     "start_time": "2025-12-14T07:50:58.519844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Hub authenticated as: vivek0620\n"
     ]
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# ---- Hugging Face ----\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "# ---- Kaggle ----\n",
    "api_token = user_secrets.get_secret(\"KAGGLE_JSON\")\n",
    "json.loads(api_token)  # validate JSON\n",
    "\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(api_token)\n",
    "\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/root/.kaggle\"\n",
    "\n",
    "print(\"Kaggle Hub authenticated as:\", kagglehub.whoami()[\"username\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf17ef8",
   "metadata": {
    "papermill": {
     "duration": 0.006845,
     "end_time": "2025-12-14T07:50:59.248273",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.241428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f0969e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.262992Z",
     "iopub.status.busy": "2025-12-14T07:50:59.262728Z",
     "iopub.status.idle": "2025-12-14T07:50:59.402485Z",
     "shell.execute_reply": "2025-12-14T07:50:59.401552Z"
    },
    "papermill": {
     "duration": 0.14925,
     "end_time": "2025-12-14T07:50:59.404243",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.254993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6535\n",
      "Val samples: 727\n",
      "Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "sampleSumbPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/sample_submission.csv'\n",
    "trainingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/train.csv'\n",
    "testingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/test.csv'\n",
    "\n",
    "trainDf = pd.read_csv(trainingDataPath)\n",
    "testDf = pd.read_csv(testingDataPath)\n",
    "sampleDf = pd.read_csv(sampleSumbPath)\n",
    "\n",
    "trainDf, valDf = train_test_split(trainDf, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train samples:\", len(trainDf))\n",
    "print(\"Val samples:\", len(valDf))\n",
    "\n",
    "\n",
    "print(\"Data Loaded Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a903ea8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.419682Z",
     "iopub.status.busy": "2025-12-14T07:50:59.419213Z",
     "iopub.status.idle": "2025-12-14T07:50:59.432401Z",
     "shell.execute_reply": "2025-12-14T07:50:59.431619Z"
    },
    "papermill": {
     "duration": 0.022554,
     "end_time": "2025-12-14T07:50:59.434071",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.411517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071</td>\n",
       "      <td>WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...</td>\n",
       "      <td>CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "      <td>CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...</td>\n",
       "      <td>CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...</td>\n",
       "      <td>CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...</td>\n",
       "      <td>CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...</td>\n",
       "      <td>CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                seq  \\\n",
       "3071  3071  WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...   \n",
       "1699  1699  HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...   \n",
       "592    592  VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...   \n",
       "\n",
       "                                                   sst8  \\\n",
       "3071  CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...   \n",
       "1699  CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...   \n",
       "592   CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...   \n",
       "\n",
       "                                                   sst3  \n",
       "3071  CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...  \n",
       "1699  CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...  \n",
       "592   CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Data....\\n\")\n",
    "trainDf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2f39b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.450193Z",
     "iopub.status.busy": "2025-12-14T07:50:59.449964Z",
     "iopub.status.idle": "2025-12-14T07:50:59.457702Z",
     "shell.execute_reply": "2025-12-14T07:50:59.456798Z"
    },
    "papermill": {
     "duration": 0.01763,
     "end_time": "2025-12-14T07:50:59.459262",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.441632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                seq\n",
       "0   0  FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...\n",
       "1   1  ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...\n",
       "2   2  VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing data....\\n\")\n",
    "testDf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d183a",
   "metadata": {
    "papermill": {
     "duration": 0.006989,
     "end_time": "2025-12-14T07:50:59.473536",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.466547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b3a1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.488992Z",
     "iopub.status.busy": "2025-12-14T07:50:59.488748Z",
     "iopub.status.idle": "2025-12-14T07:50:59.493697Z",
     "shell.execute_reply": "2025-12-14T07:50:59.493043Z"
    },
    "papermill": {
     "duration": 0.014562,
     "end_time": "2025-12-14T07:50:59.495283",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.480721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 20 standard AAs + X (unknown)\n",
    "AAs = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "aa2id = {a: i + 1 for i, a in enumerate(AAs)}\n",
    "aa2id[\"X\"] = len(aa2id) + 1  # unknown / masked\n",
    "id2aa = {i: a for a, i in aa2id.items()}\n",
    "\n",
    "# Q8 labels (DSSP)\n",
    "sst8_chars = list(\"CHES TBIG\".replace(\" \", \"\"))  # C H E S T B I G\n",
    "sst8_map = {c: i for i, c in enumerate(sst8_chars)}\n",
    "id2sst8 = {i: c for c, i in sst8_map.items()}\n",
    "\n",
    "# Q3 labels\n",
    "sst3_chars = list(\"CHE\")  # C=coil, H=helix, E=strand\n",
    "sst3_map = {c: i for i, c in enumerate(sst3_chars)}\n",
    "id2sst3 = {i: c for c, i in sst3_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072ec76",
   "metadata": {
    "papermill": {
     "duration": 0.007212,
     "end_time": "2025-12-14T07:50:59.509724",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.502512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f57839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.524944Z",
     "iopub.status.busy": "2025-12-14T07:50:59.524654Z",
     "iopub.status.idle": "2025-12-14T07:50:59.533218Z",
     "shell.execute_reply": "2025-12-14T07:50:59.532518Z"
    },
    "papermill": {
     "duration": 0.017805,
     "end_time": "2025-12-14T07:50:59.534797",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.516992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_sequence(seq):\n",
    "    return re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Clean sequences\n",
    "        self.seq = [clean_sequence(s) for s in df[\"seq\"].tolist()]\n",
    "        self.s8  = df[\"sst8\"].tolist()\n",
    "        self.s3  = df[\"sst3\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Amino acid encoding\n",
    "        x = torch.tensor(\n",
    "            [aa2id.get(a, aa2id[\"X\"]) for a in self.seq[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q8 labels\n",
    "        y8 = torch.tensor(\n",
    "            [sst8_map[c] for c in self.s8[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q3 labels\n",
    "        y3 = torch.tensor(\n",
    "            [sst3_map[c] for c in self.s3[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return x, y8, y3\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    xs, y8s, y3s = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "\n",
    "    xs  = pad_sequence(xs,  batch_first=True, padding_value=0)\n",
    "    y8s = pad_sequence(y8s, batch_first=True, padding_value=-1)\n",
    "    y3s = pad_sequence(y3s, batch_first=True, padding_value=-1)\n",
    "\n",
    "    return xs, lengths, y8s, y3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56c0b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.550509Z",
     "iopub.status.busy": "2025-12-14T07:50:59.550293Z",
     "iopub.status.idle": "2025-12-14T07:50:59.571547Z",
     "shell.execute_reply": "2025-12-14T07:50:59.570983Z"
    },
    "papermill": {
     "duration": 0.030873,
     "end_time": "2025-12-14T07:50:59.573052",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.542179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDs = ProteinDataset(trainDf)\n",
    "valDs   = ProteinDataset(valDf)\n",
    "\n",
    "trainLoader = DataLoader(trainDs, batch_size=1, shuffle=True, collate_fn=collate)\n",
    "valLoader   = DataLoader(valDs,   batch_size=1, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e417aa8",
   "metadata": {
    "papermill": {
     "duration": 0.007482,
     "end_time": "2025-12-14T07:50:59.587936",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.580454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d7b10",
   "metadata": {
    "papermill": {
     "duration": 0.007141,
     "end_time": "2025-12-14T07:50:59.602169",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.595028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional RNN (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf13795e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.617740Z",
     "iopub.status.busy": "2025-12-14T07:50:59.617492Z",
     "iopub.status.idle": "2025-12-14T07:50:59.624101Z",
     "shell.execute_reply": "2025-12-14T07:50:59.623471Z"
    },
    "papermill": {
     "duration": 0.016356,
     "end_time": "2025-12-14T07:50:59.625809",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.609453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiRNN(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.rnn = nn.RNN(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.rnn(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embed_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,\n",
    "        dropout=0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embed_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            nonlinearity=\"tanh\",\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc8 = nn.Linear(hidden_dim * 2, 8)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "\n",
    "        packed = pack_padded_sequence(\n",
    "            x,\n",
    "            lengths.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        packed_out, _ = self.rnn(packed)\n",
    "\n",
    "        h, _ = pad_packed_sequence(\n",
    "            packed_out,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        h = self.norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        p8 = self.fc8(h)\n",
    "        p3 = self.fc3(h)\n",
    "\n",
    "        return p8, p3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201384ed",
   "metadata": {
    "papermill": {
     "duration": 0.007199,
     "end_time": "2025-12-14T07:50:59.640097",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.632898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8262b79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.655113Z",
     "iopub.status.busy": "2025-12-14T07:50:59.654886Z",
     "iopub.status.idle": "2025-12-14T07:50:59.661449Z",
     "shell.execute_reply": "2025-12-14T07:50:59.660698Z"
    },
    "papermill": {
     "duration": 0.015865,
     "end_time": "2025-12-14T07:50:59.663109",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.647244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiLSTM(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.lstm(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, hidden=256, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed, hidden, num_layers=num_layers, bidirectional=True, \n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc8 = nn.Linear(hidden * 2, 8)\n",
    "        self.fc3 = nn.Linear(hidden * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "\n",
    "        h, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        out8 = self.fc8(h)\n",
    "        out3 = self.fc3(h)\n",
    "\n",
    "        return out8, out3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4ba5b",
   "metadata": {
    "papermill": {
     "duration": 0.007086,
     "end_time": "2025-12-14T07:50:59.677632",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.670546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Selecting Device (GPU/CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb2969",
   "metadata": {
    "papermill": {
     "duration": 0.007004,
     "end_time": "2025-12-14T07:50:59.691648",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.684644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking Available Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f8196c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.707297Z",
     "iopub.status.busy": "2025-12-14T07:50:59.707082Z",
     "iopub.status.idle": "2025-12-14T07:50:59.824780Z",
     "shell.execute_reply": "2025-12-14T07:50:59.823802Z"
    },
    "papermill": {
     "duration": 0.12749,
     "end_time": "2025-12-14T07:50:59.826582",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.699092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA GPUs available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU — CPU will be used.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c0d07",
   "metadata": {
    "papermill": {
     "duration": 0.007265,
     "end_time": "2025-12-14T07:50:59.841393",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.834128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selecting GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214af1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.857057Z",
     "iopub.status.busy": "2025-12-14T07:50:59.856792Z",
     "iopub.status.idle": "2025-12-14T07:50:59.861438Z",
     "shell.execute_reply": "2025-12-14T07:50:59.860711Z"
    },
    "papermill": {
     "duration": 0.014526,
     "end_time": "2025-12-14T07:50:59.863196",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.848670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d59bd",
   "metadata": {
    "papermill": {
     "duration": 0.007321,
     "end_time": "2025-12-14T07:50:59.917047",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.909726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function, and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb230fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.932802Z",
     "iopub.status.busy": "2025-12-14T07:50:59.932485Z",
     "iopub.status.idle": "2025-12-14T07:50:59.936468Z",
     "shell.execute_reply": "2025-12-14T07:50:59.935752Z"
    },
    "papermill": {
     "duration": 0.013781,
     "end_time": "2025-12-14T07:50:59.937980",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.924199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "def harmonic_mean(a, b):\n",
    "    return 2 / (1/a + 1/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d20a485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.953718Z",
     "iopub.status.busy": "2025-12-14T07:50:59.953228Z",
     "iopub.status.idle": "2025-12-14T07:50:59.959960Z",
     "shell.execute_reply": "2025-12-14T07:50:59.959196Z"
    },
    "papermill": {
     "duration": 0.016367,
     "end_time": "2025-12-14T07:50:59.961577",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.945210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataLoader):\n",
    "    model.eval()\n",
    "\n",
    "    all8_true, all8_pred = [], []\n",
    "    all3_true, all3_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, lengths, y8, y3 in dataLoader:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1).view(-1)\n",
    "            pred3 = p3.argmax(dim=-1).view(-1)\n",
    "\n",
    "            y8_flat = y8.view(-1)\n",
    "            y3_flat = y3.view(-1)\n",
    "\n",
    "            mask8 = (y8_flat != -1)\n",
    "            mask3 = (y3_flat != -1)\n",
    "\n",
    "            all8_true.extend(y8_flat[mask8].cpu().tolist())\n",
    "            all8_pred.extend(pred8[mask8].cpu().tolist())\n",
    "\n",
    "            all3_true.extend(y3_flat[mask3].cpu().tolist())\n",
    "            all3_pred.extend(pred3[mask3].cpu().tolist())\n",
    "\n",
    "    f18 = f1_score(all8_true, all8_pred, average=\"macro\")\n",
    "    f13 = f1_score(all3_true, all3_pred, average=\"macro\")\n",
    "    hm = harmonic_mean(f18, f13)\n",
    "\n",
    "    return f18, f13, hm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c863e",
   "metadata": {
    "papermill": {
     "duration": 0.007185,
     "end_time": "2025-12-14T07:50:59.976291",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.969106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b01005f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:50:59.991964Z",
     "iopub.status.busy": "2025-12-14T07:50:59.991555Z",
     "iopub.status.idle": "2025-12-14T07:51:00.001047Z",
     "shell.execute_reply": "2025-12-14T07:51:00.000279Z"
    },
    "papermill": {
     "duration": 0.019407,
     "end_time": "2025-12-14T07:51:00.002820",
     "exception": false,
     "start_time": "2025-12-14T07:50:59.983413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    epochs=10,\n",
    "    w8=1.5,   # weight for Q8\n",
    "    w3=1.0    # weight for Q3\n",
    "):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        batch_bar = tqdm(\n",
    "            trainLoader,\n",
    "            desc=f\"Epoch {ep+1}/{epochs}\",\n",
    "            mininterval=0.5\n",
    "        )\n",
    "\n",
    "        total_loss_ep = 0.0\n",
    "        total_loss8_ep = 0.0\n",
    "        total_loss3_ep = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for x, lengths, y8, y3 in batch_bar:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            # flatten for CE loss\n",
    "            loss8 = criterion(p8.view(-1, 8), y8.view(-1))\n",
    "            loss3 = criterion(p3.view(-1, 3), y3.view(-1))\n",
    "\n",
    "            total_loss = w8 * loss8 + w3 * loss3\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_ep += total_loss.item()\n",
    "            total_loss8_ep += loss8.item()\n",
    "            total_loss3_ep += loss3.item()\n",
    "            total_batches += 1\n",
    "\n",
    "            batch_bar.set_postfix({\n",
    "                \"loss8\": f\"{loss8.item():.4f}\",\n",
    "                \"loss3\": f\"{loss3.item():.4f}\",\n",
    "                \"total\": f\"{total_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "        # ---- Validation ----\n",
    "        f18, f13, hm = evaluate(model, valLoader)\n",
    "\n",
    "        avg_loss = total_loss_ep / total_batches\n",
    "        avg_loss8 = total_loss8_ep / total_batches\n",
    "        avg_loss3 = total_loss3_ep / total_batches\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {ep+1} Validation | \"\n",
    "            f\"F1-8={f18:.4f} | F1-3={f13:.4f} | HM={hm:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(hm)\n",
    "\n",
    "        # TrackIO logging (corrected)\n",
    "        trackio.log({\n",
    "            \"epoch\": ep + 1,\n",
    "            \"loss_epoch\": avg_loss,\n",
    "            \"loss8_epoch\": avg_loss8,\n",
    "            \"loss3_epoch\": avg_loss3,\n",
    "            \"val_F1_8\": f18,\n",
    "            \"val_F1_3\": f13,\n",
    "            \"val_harmonic_mean\": hm\n",
    "        })\n",
    "\n",
    "    trackio.finish()\n",
    "    print(\"Training finished & logged to TrackIO.\\n\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2612a",
   "metadata": {
    "papermill": {
     "duration": 0.00726,
     "end_time": "2025-12-14T07:51:00.017694",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.010434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5d1be",
   "metadata": {
    "papermill": {
     "duration": 0.007177,
     "end_time": "2025-12-14T07:51:00.032029",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.024852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Switcher / Control - Training and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d94af01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:51:00.047749Z",
     "iopub.status.busy": "2025-12-14T07:51:00.047487Z",
     "iopub.status.idle": "2025-12-14T07:51:00.050840Z",
     "shell.execute_reply": "2025-12-14T07:51:00.050070Z"
    },
    "papermill": {
     "duration": 0.013199,
     "end_time": "2025-12-14T07:51:00.052586",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.039387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "canTrain = True\n",
    "canTrainBiRNN = True\n",
    "canTrainBiLSTM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07d527",
   "metadata": {
    "papermill": {
     "duration": 0.007528,
     "end_time": "2025-12-14T07:51:00.067809",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.060281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Trackio Initialization and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "159fc9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:51:00.083418Z",
     "iopub.status.busy": "2025-12-14T07:51:00.083195Z",
     "iopub.status.idle": "2025-12-14T07:51:00.090050Z",
     "shell.execute_reply": "2025-12-14T07:51:00.089290Z"
    },
    "papermill": {
     "duration": 0.016465,
     "end_time": "2025-12-14T07:51:00.091614",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.075149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAGGLE_USERNAME = \"vivek0620\"\n",
    "FRAMEWORK = \"pytorch\"\n",
    "\n",
    "def trackioInit(run_name, group, optimizer, batch_size=1, extra_config=None):\n",
    "\n",
    "    # Base config\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "    }\n",
    "\n",
    "    # Merge extra hyperparameters, if provided\n",
    "    if extra_config is not None:\n",
    "        config.update(extra_config)\n",
    "\n",
    "    # Initialize TrackIO\n",
    "    trackio.init(\n",
    "        project=\"25-t3-nppe2\",\n",
    "        space_id=\"bytescode/dlgenai-nppe\",\n",
    "        name=run_name,\n",
    "        group=group,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    print(f\"[TrackIO] Run initialized → {run_name} (Group: {group})\")\n",
    "\n",
    "\n",
    "def get_model_params(model, optimizer):\n",
    "    # ---- Embedding ----\n",
    "    if hasattr(model, \"embedding\"):\n",
    "        embed_dim = model.embedding.embedding_dim\n",
    "    elif hasattr(model, \"emb\"):\n",
    "        embed_dim = model.emb.embedding_dim\n",
    "    else:\n",
    "        embed_dim = None  # e.g. transformer with external embeddings\n",
    "\n",
    "    # ---- Learning rate ----\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # ---- Model type detection ----\n",
    "    if hasattr(model, \"lstm\"):\n",
    "        hidden_dim = model.lstm.hidden_size\n",
    "        layers = model.lstm.num_layers\n",
    "        model_type = \"BiLSTM\"\n",
    "\n",
    "    elif hasattr(model, \"rnn\"):\n",
    "        hidden_dim = model.rnn.hidden_size\n",
    "        layers = model.rnn.num_layers\n",
    "        model_type = \"BiRNN\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported model: expected attribute 'lstm' or 'rnn'\"\n",
    "        )\n",
    "\n",
    "    return model_type, hidden_dim, embed_dim, layers, lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2583c",
   "metadata": {
    "papermill": {
     "duration": 0.007436,
     "end_time": "2025-12-14T07:51:00.106533",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.099097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45d964e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:51:00.122407Z",
     "iopub.status.busy": "2025-12-14T07:51:00.122183Z",
     "iopub.status.idle": "2025-12-14T07:51:00.191980Z",
     "shell.execute_reply": "2025-12-14T07:51:00.191390Z"
    },
    "papermill": {
     "duration": 0.079598,
     "end_time": "2025-12-14T07:51:00.193687",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.114089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(aa2id) + 1\n",
    "\n",
    "birnn = BiRNN(vocab_size)\n",
    "bilstm = BiLSTM(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2db5",
   "metadata": {
    "papermill": {
     "duration": 0.007474,
     "end_time": "2025-12-14T07:51:00.210006",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.202532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-RNN & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bb4d026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T07:51:00.225847Z",
     "iopub.status.busy": "2025-12-14T07:51:00.225356Z",
     "iopub.status.idle": "2025-12-14T08:22:08.017090Z",
     "shell.execute_reply": "2025-12-14T08:22:08.016018Z"
    },
    "papermill": {
     "duration": 1869.888661,
     "end_time": "2025-12-14T08:22:10.106076",
     "exception": false,
     "start_time": "2025-12-14T07:51:00.217415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiRNN...\n",
      "Run name: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "* Trackio project initialized: 25-t3-nppe2\n",
      "* Trackio metrics will be synced to Hugging Face Dataset: bytescode/dlgenai-nppe-dataset\n",
      "* Found existing space: https://huggingface.co/spaces/bytescode/dlgenai-nppe\n",
      "* View dashboard by going to: https://bytescode-dlgenai-nppe.hf.space/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bytescode-dlgenai-nppe.hf.space/\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Created new run: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiRNN-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.16it/s, loss8=1.7434, loss3=1.0915, total=3.7066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.2772 | F1-3=0.6690 | HM=0.3920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.32it/s, loss8=1.2187, loss3=0.7724, total=2.6004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.2931 | F1-3=0.6742 | HM=0.4085\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11: 100%|██████████| 6535/6535 [02:41<00:00, 40.38it/s, loss8=1.5957, loss3=0.7968, total=3.1903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.2903 | F1-3=0.6819 | HM=0.4072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.31it/s, loss8=0.8774, loss3=0.5891, total=1.9052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.2967 | F1-3=0.6780 | HM=0.4127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11: 100%|██████████| 6535/6535 [02:43<00:00, 40.04it/s, loss8=0.8066, loss3=0.4281, total=1.6380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3091 | F1-3=0.6821 | HM=0.4254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.17it/s, loss8=1.1970, loss3=0.6505, total=2.4459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.3114 | F1-3=0.6772 | HM=0.4266\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.23it/s, loss8=1.2865, loss3=0.7417, total=2.6715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.2993 | F1-3=0.6725 | HM=0.4143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11: 100%|██████████| 6535/6535 [02:41<00:00, 40.34it/s, loss8=1.1144, loss3=0.6596, total=2.3312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3047 | F1-3=0.6856 | HM=0.4219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.26it/s, loss8=0.9801, loss3=0.5546, total=2.0248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3011 | F1-3=0.6839 | HM=0.4181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11: 100%|██████████| 6535/6535 [02:42<00:00, 40.14it/s, loss8=1.6737, loss3=0.9761, total=3.4866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3099 | F1-3=0.6846 | HM=0.4267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11: 100%|██████████| 6535/6535 [02:41<00:00, 40.35it/s, loss8=1.1579, loss3=0.5954, total=2.3323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3053 | F1-3=0.6879 | HM=0.4229\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiRNN-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiRNN:\n",
    "    print(\"Training BiRNN...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(birnn.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 11\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        birnn, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "\n",
    "    birnn_model = train_model(model=birnn, optimizer=optimizer, criterion=criterion, \n",
    "                              scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(birnn_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping BiRNN training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a69036",
   "metadata": {
    "papermill": {
     "duration": 3.591559,
     "end_time": "2025-12-14T08:22:17.488206",
     "exception": false,
     "start_time": "2025-12-14T08:22:13.896647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-LSTM & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159eec9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:22:24.733121Z",
     "iopub.status.busy": "2025-12-14T08:22:24.732462Z",
     "iopub.status.idle": "2025-12-14T08:54:43.354566Z",
     "shell.execute_reply": "2025-12-14T08:54:43.353610Z"
    },
    "papermill": {
     "duration": 1942.148882,
     "end_time": "2025-12-14T08:54:43.356486",
     "exception": false,
     "start_time": "2025-12-14T08:22:21.207604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM...\n",
      "Run name: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "* Created new run: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiLSTM-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11: 100%|██████████| 6535/6535 [02:50<00:00, 38.44it/s, loss8=1.1597, loss3=0.7096, total=2.4492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.3004 | F1-3=0.6865 | HM=0.4180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.83it/s, loss8=1.0727, loss3=0.5766, total=2.1857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.3159 | F1-3=0.6955 | HM=0.4345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.69it/s, loss8=1.1774, loss3=0.7493, total=2.5154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.3053 | F1-3=0.6994 | HM=0.4251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.76it/s, loss8=1.2358, loss3=0.8775, total=2.7312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.3209 | F1-3=0.7068 | HM=0.4414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.72it/s, loss8=0.9954, loss3=0.5896, total=2.0828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3228 | F1-3=0.7081 | HM=0.4434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.68it/s, loss8=0.6306, loss3=0.3893, total=1.3352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.3202 | F1-3=0.7081 | HM=0.4410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11: 100%|██████████| 6535/6535 [02:49<00:00, 38.58it/s, loss8=0.7782, loss3=0.5538, total=1.7211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.3295 | F1-3=0.7052 | HM=0.4491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.69it/s, loss8=0.8174, loss3=0.5840, total=1.8101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3250 | F1-3=0.7068 | HM=0.4452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.78it/s, loss8=0.5503, loss3=0.3046, total=1.1300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3286 | F1-3=0.7061 | HM=0.4485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11: 100%|██████████| 6535/6535 [02:49<00:00, 38.51it/s, loss8=0.9738, loss3=0.3954, total=1.8561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3282 | F1-3=0.7019 | HM=0.4473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11: 100%|██████████| 6535/6535 [02:48<00:00, 38.88it/s, loss8=0.8985, loss3=0.5145, total=1.8623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3345 | F1-3=0.7039 | HM=0.4535\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiLSTM-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiLSTM:\n",
    "    print(\"Training BiLSTM...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(bilstm.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 11\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        bilstm, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "\n",
    "    bilstm_model = train_model(model=bilstm, optimizer=optimizer, criterion=criterion,\n",
    "        scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(bilstm_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf16763",
   "metadata": {
    "papermill": {
     "duration": 7.295274,
     "end_time": "2025-12-14T08:54:58.071534",
     "exception": false,
     "start_time": "2025-12-14T08:54:50.776260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc821937",
   "metadata": {
    "papermill": {
     "duration": 7.360818,
     "end_time": "2025-12-14T08:55:12.854435",
     "exception": false,
     "start_time": "2025-12-14T08:55:05.493617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d2b47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:55:27.788501Z",
     "iopub.status.busy": "2025-12-14T08:55:27.788179Z",
     "iopub.status.idle": "2025-12-14T08:55:42.063003Z",
     "shell.execute_reply": "2025-12-14T08:55:42.062161Z"
    },
    "papermill": {
     "duration": 21.771954,
     "end_time": "2025-12-14T08:55:42.065217",
     "exception": false,
     "start_time": "2025-12-14T08:55:20.293263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL COMPARISON ===\n",
      "\n",
      "BiRNN  → F1-8=0.3053 | F1-3=0.6879 | HM=0.4229\n",
      "BiLSTM → F1-8=0.3345 | F1-3=0.7039 | HM=0.4535\n",
      "\n",
      ">>> BiLSTM is better overall.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MODEL COMPARISON ===\\n\")\n",
    "\n",
    "birnn_f18, birnn_f13, birnn_hm = evaluate(birnn_model, valLoader)\n",
    "bilstm_f18, bilstm_f13, bilstm_hm = evaluate(bilstm_model, valLoader)\n",
    "\n",
    "print(f\"BiRNN  → F1-8={birnn_f18:.4f} | F1-3={birnn_f13:.4f} | HM={birnn_hm:.4f}\")\n",
    "print(f\"BiLSTM → F1-8={bilstm_f18:.4f} | F1-3={bilstm_f13:.4f} | HM={bilstm_hm:.4f}\")\n",
    "\n",
    "if bilstm_hm > birnn_hm:\n",
    "    print(\"\\n>>> BiLSTM is better overall.\")\n",
    "else:\n",
    "    print(\"\\n>>> BiRNN is better overall.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22b983",
   "metadata": {
    "papermill": {
     "duration": 7.284575,
     "end_time": "2025-12-14T08:55:56.645274",
     "exception": false,
     "start_time": "2025-12-14T08:55:49.360699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selection Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4edea5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:56:11.307363Z",
     "iopub.status.busy": "2025-12-14T08:56:11.306698Z",
     "iopub.status.idle": "2025-12-14T08:56:11.311804Z",
     "shell.execute_reply": "2025-12-14T08:56:11.310997Z"
    },
    "papermill": {
     "duration": 7.285831,
     "end_time": "2025-12-14T08:56:11.313675",
     "exception": false,
     "start_time": "2025-12-14T08:56:04.027844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Best model selected: BiLSTM\n"
     ]
    }
   ],
   "source": [
    "if bilstm_hm > birnn_hm:\n",
    "    best_model = bilstm_model\n",
    "    best_name = \"BiLSTM\"\n",
    "else:\n",
    "    best_model = birnn_model\n",
    "    best_name = \"BiRNN\"\n",
    "\n",
    "print(f\"\\n>>> Best model selected: {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b262a46",
   "metadata": {
    "papermill": {
     "duration": 7.295526,
     "end_time": "2025-12-14T08:56:26.075471",
     "exception": false,
     "start_time": "2025-12-14T08:56:18.779945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a139825c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:56:40.874181Z",
     "iopub.status.busy": "2025-12-14T08:56:40.873410Z",
     "iopub.status.idle": "2025-12-14T08:56:40.880353Z",
     "shell.execute_reply": "2025-12-14T08:56:40.879519Z"
    },
    "papermill": {
     "duration": 7.465256,
     "end_time": "2025-12-14T08:56:40.882025",
     "exception": false,
     "start_time": "2025-12-14T08:56:33.416769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    model.eval()\n",
    "\n",
    "    seqs8, seqs3 = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq in df[\"seq\"]:\n",
    "            # Clean sequence (important!)\n",
    "            seq = re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "            # Encode\n",
    "            x = torch.tensor(\n",
    "                [aa2id.get(a, aa2id[\"X\"]) for a in seq],\n",
    "                dtype=torch.long\n",
    "            ).unsqueeze(0).to(device)\n",
    "\n",
    "            lengths = torch.tensor([len(seq)], dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1)[0].tolist()\n",
    "            pred3 = p3.argmax(dim=-1)[0].tolist()\n",
    "\n",
    "            # Decode → characters\n",
    "            s8 = \"\".join(id2sst8[i] for i in pred8)\n",
    "            s3 = \"\".join(id2sst3[i] for i in pred3)\n",
    "\n",
    "            seqs8.append(s8)\n",
    "            seqs3.append(s3)\n",
    "\n",
    "    return seqs8, seqs3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331b856",
   "metadata": {
    "papermill": {
     "duration": 7.268675,
     "end_time": "2025-12-14T08:56:55.489228",
     "exception": false,
     "start_time": "2025-12-14T08:56:48.220553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict (sst8 & sst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03e8f885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:57:10.153268Z",
     "iopub.status.busy": "2025-12-14T08:57:10.152880Z",
     "iopub.status.idle": "2025-12-14T08:57:26.209985Z",
     "shell.execute_reply": "2025-12-14T08:57:26.209252Z"
    },
    "papermill": {
     "duration": 23.34201,
     "end_time": "2025-12-14T08:57:26.211741",
     "exception": false,
     "start_time": "2025-12-14T08:57:02.869731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_s8, test_s3 = predict(best_model, testDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fdbff",
   "metadata": {
    "papermill": {
     "duration": 7.40874,
     "end_time": "2025-12-14T08:57:40.961714",
     "exception": false,
     "start_time": "2025-12-14T08:57:33.552974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09810da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:57:55.595226Z",
     "iopub.status.busy": "2025-12-14T08:57:55.594906Z",
     "iopub.status.idle": "2025-12-14T08:57:55.631881Z",
     "shell.execute_reply": "2025-12-14T08:57:55.631070Z"
    },
    "papermill": {
     "duration": 7.297169,
     "end_time": "2025-12-14T08:57:55.633477",
     "exception": false,
     "start_time": "2025-12-14T08:57:48.336308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCCCCTHHHHHHHHHHHHHHHHHCEEEEEEETTCTCCCSEEEEECT...</td>\n",
       "      <td>CCCCCCHHHHHHHHHHHHHHHHHCEEEEEECCCCCCCCCEEEEECC...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CCCCCCCCCCCCCEEEECSTTCEEEEEECTTEEEEHHHHCCCTHGG...</td>\n",
       "      <td>CCCCCCCCCCCCCEEEECCCCCEEEEECCCCHEEHHHHHCCCCHHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CTHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHCCCCSHHHHHHHHH...</td>\n",
       "      <td>CCHHHHHHHHCHHHHHHHHHHHHHHHHHHHHHCCCCCHHHHHHHHH...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CCCTTHHHHHHHHHHHHHHHHHHHHHHHCCEEECHTHHHHHHHHHH...</td>\n",
       "      <td>CCCCCHHHHHHHHHHHHHHHHHHHHHHHCCEEECCCHHHHHHHHHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CEEEEEEGGCCTHHHHHHHHHHHHHHHCCEEEECSTTEEEEEEEEE...</td>\n",
       "      <td>CEEEEEECCCCCHHHHHHHHHHHHHHHCCEEEECCCCEEEEEECEE...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               sst8  \\\n",
       "0   0  CCCCCTHHHHHHHHHHHHHHHHHCEEEEEEETTCTCCCSEEEEECT...   \n",
       "1   1  CCCCCCCCCCCCCEEEECSTTCEEEEEECTTEEEEHHHHCCCTHGG...   \n",
       "2   2  CTHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHCCCCSHHHHHHHHH...   \n",
       "3   3  CCCTTHHHHHHHHHHHHHHHHHHHHHHHCCEEECHTHHHHHHHHHH...   \n",
       "4   4  CEEEEEEGGCCTHHHHHHHHHHHHHHHCCEEEECSTTEEEEEEEEE...   \n",
       "\n",
       "                                                sst3    Usage  \n",
       "0  CCCCCCHHHHHHHHHHHHHHHHHCEEEEEECCCCCCCCCEEEEECC...  Private  \n",
       "1  CCCCCCCCCCCCCEEEECCCCCEEEEECCCCHEEHHHHHCCCCHHH...  Private  \n",
       "2  CCHHHHHHHHCHHHHHHHHHHHHHHHHHHHHHCCCCCHHHHHHHHH...   Public  \n",
       "3  CCCCCHHHHHHHHHHHHHHHHHHHHHHHCCEEECCCHHHHHHHHHH...  Private  \n",
       "4  CEEEEEECCCCCHHHHHHHHHHHHHHHCCEEEECCCCEEEEEECEE...  Private  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sampleDf.copy()\n",
    "\n",
    "submission[\"sst8\"] = test_s8\n",
    "submission[\"sst3\"] = test_s3\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv\\n\")\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14858151,
     "sourceId": 125543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4078.211649,
   "end_time": "2025-12-14T08:58:05.341977",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T07:50:07.130328",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
