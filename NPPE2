{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5581fda5",
   "metadata": {
    "papermill": {
     "duration": 0.008481,
     "end_time": "2025-12-14T11:20:28.316037",
     "exception": false,
     "start_time": "2025-12-14T11:20:28.307556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909876ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:20:28.335800Z",
     "iopub.status.busy": "2025-12-14T11:20:28.335010Z",
     "iopub.status.idle": "2025-12-14T11:21:39.515335Z",
     "shell.execute_reply": "2025-12-14T11:21:39.514188Z"
    },
    "papermill": {
     "duration": 71.200544,
     "end_time": "2025-12-14T11:21:39.525690",
     "exception": false,
     "start_time": "2025-12-14T11:20:28.325146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trackio -qqq > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6dc497",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:39.544696Z",
     "iopub.status.busy": "2025-12-14T11:21:39.543845Z",
     "iopub.status.idle": "2025-12-14T11:21:54.564070Z",
     "shell.execute_reply": "2025-12-14T11:21:54.563284Z"
    },
    "papermill": {
     "duration": 15.03207,
     "end_time": "2025-12-14T11:21:54.565889",
     "exception": false,
     "start_time": "2025-12-14T11:21:39.533819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Imports Done, Good to go....\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trackio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import subprocess\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import kagglehub\n",
    "\n",
    "print(\"All Imports Done, Good to go....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350538c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:54.582587Z",
     "iopub.status.busy": "2025-12-14T11:21:54.582050Z",
     "iopub.status.idle": "2025-12-14T11:21:54.879053Z",
     "shell.execute_reply": "2025-12-14T11:21:54.877983Z"
    },
    "papermill": {
     "duration": 0.30708,
     "end_time": "2025-12-14T11:21:54.881284",
     "exception": false,
     "start_time": "2025-12-14T11:21:54.574204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Hub authenticated as: vivek0620\n"
     ]
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# ---- Hugging Face ----\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "# ---- Kaggle ----\n",
    "api_token = user_secrets.get_secret(\"KAGGLE_JSON\")\n",
    "json.loads(api_token)  # validate JSON\n",
    "\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(api_token)\n",
    "\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/root/.kaggle\"\n",
    "\n",
    "print(\"Kaggle Hub authenticated as:\", kagglehub.whoami()[\"username\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c30a54",
   "metadata": {
    "papermill": {
     "duration": 0.008111,
     "end_time": "2025-12-14T11:21:54.898178",
     "exception": false,
     "start_time": "2025-12-14T11:21:54.890067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76f5f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:54.916420Z",
     "iopub.status.busy": "2025-12-14T11:21:54.916061Z",
     "iopub.status.idle": "2025-12-14T11:21:55.125429Z",
     "shell.execute_reply": "2025-12-14T11:21:55.124393Z"
    },
    "papermill": {
     "duration": 0.221096,
     "end_time": "2025-12-14T11:21:55.127585",
     "exception": false,
     "start_time": "2025-12-14T11:21:54.906489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6535\n",
      "Val samples: 727\n",
      "Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "sampleSumbPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/sample_submission.csv'\n",
    "trainingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/train.csv'\n",
    "testingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/test.csv'\n",
    "\n",
    "trainDf = pd.read_csv(trainingDataPath)\n",
    "testDf = pd.read_csv(testingDataPath)\n",
    "sampleDf = pd.read_csv(sampleSumbPath)\n",
    "\n",
    "trainDf, valDf = train_test_split(trainDf, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train samples:\", len(trainDf))\n",
    "print(\"Val samples:\", len(valDf))\n",
    "\n",
    "\n",
    "print(\"Data Loaded Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbb7298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.145251Z",
     "iopub.status.busy": "2025-12-14T11:21:55.144927Z",
     "iopub.status.idle": "2025-12-14T11:21:55.162922Z",
     "shell.execute_reply": "2025-12-14T11:21:55.162023Z"
    },
    "papermill": {
     "duration": 0.029162,
     "end_time": "2025-12-14T11:21:55.165123",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.135961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071</td>\n",
       "      <td>WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...</td>\n",
       "      <td>CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "      <td>CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...</td>\n",
       "      <td>CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...</td>\n",
       "      <td>CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...</td>\n",
       "      <td>CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...</td>\n",
       "      <td>CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                seq  \\\n",
       "3071  3071  WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...   \n",
       "1699  1699  HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...   \n",
       "592    592  VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...   \n",
       "\n",
       "                                                   sst8  \\\n",
       "3071  CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...   \n",
       "1699  CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...   \n",
       "592   CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...   \n",
       "\n",
       "                                                   sst3  \n",
       "3071  CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...  \n",
       "1699  CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...  \n",
       "592   CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Data....\\n\")\n",
    "trainDf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98a859e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.184107Z",
     "iopub.status.busy": "2025-12-14T11:21:55.183119Z",
     "iopub.status.idle": "2025-12-14T11:21:55.193470Z",
     "shell.execute_reply": "2025-12-14T11:21:55.192379Z"
    },
    "papermill": {
     "duration": 0.021546,
     "end_time": "2025-12-14T11:21:55.195632",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.174086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                seq\n",
       "0   0  FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...\n",
       "1   1  ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...\n",
       "2   2  VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing data....\\n\")\n",
    "testDf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5140d",
   "metadata": {
    "papermill": {
     "duration": 0.008954,
     "end_time": "2025-12-14T11:21:55.214570",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.205616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9ff692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.234510Z",
     "iopub.status.busy": "2025-12-14T11:21:55.234106Z",
     "iopub.status.idle": "2025-12-14T11:21:55.240682Z",
     "shell.execute_reply": "2025-12-14T11:21:55.239732Z"
    },
    "papermill": {
     "duration": 0.018956,
     "end_time": "2025-12-14T11:21:55.242639",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.223683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 20 standard AAs + X (unknown)\n",
    "AAs = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "aa2id = {a: i + 1 for i, a in enumerate(AAs)}\n",
    "aa2id[\"X\"] = len(aa2id) + 1  # unknown / masked\n",
    "id2aa = {i: a for a, i in aa2id.items()}\n",
    "\n",
    "# Q8 labels (DSSP)\n",
    "sst8_chars = list(\"CHES TBIG\".replace(\" \", \"\"))  # C H E S T B I G\n",
    "sst8_map = {c: i for i, c in enumerate(sst8_chars)}\n",
    "id2sst8 = {i: c for c, i in sst8_map.items()}\n",
    "\n",
    "# Q3 labels\n",
    "sst3_chars = list(\"CHE\")  # C=coil, H=helix, E=strand\n",
    "sst3_map = {c: i for i, c in enumerate(sst3_chars)}\n",
    "id2sst3 = {i: c for c, i in sst3_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7926c94",
   "metadata": {
    "papermill": {
     "duration": 0.008121,
     "end_time": "2025-12-14T11:21:55.259942",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.251821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77dbfb2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.277867Z",
     "iopub.status.busy": "2025-12-14T11:21:55.277537Z",
     "iopub.status.idle": "2025-12-14T11:21:55.287122Z",
     "shell.execute_reply": "2025-12-14T11:21:55.286350Z"
    },
    "papermill": {
     "duration": 0.020644,
     "end_time": "2025-12-14T11:21:55.288849",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.268205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_sequence(seq):\n",
    "    return re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Clean sequences\n",
    "        self.seq = [clean_sequence(s) for s in df[\"seq\"].tolist()]\n",
    "        self.s8  = df[\"sst8\"].tolist()\n",
    "        self.s3  = df[\"sst3\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Amino acid encoding\n",
    "        x = torch.tensor(\n",
    "            [aa2id.get(a, aa2id[\"X\"]) for a in self.seq[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q8 labels\n",
    "        y8 = torch.tensor(\n",
    "            [sst8_map[c] for c in self.s8[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q3 labels\n",
    "        y3 = torch.tensor(\n",
    "            [sst3_map[c] for c in self.s3[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return x, y8, y3\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    xs, y8s, y3s = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "\n",
    "    xs  = pad_sequence(xs,  batch_first=True, padding_value=0)\n",
    "    y8s = pad_sequence(y8s, batch_first=True, padding_value=-1)\n",
    "    y3s = pad_sequence(y3s, batch_first=True, padding_value=-1)\n",
    "\n",
    "    return xs, lengths, y8s, y3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab08a515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.304896Z",
     "iopub.status.busy": "2025-12-14T11:21:55.304651Z",
     "iopub.status.idle": "2025-12-14T11:21:55.327101Z",
     "shell.execute_reply": "2025-12-14T11:21:55.326337Z"
    },
    "papermill": {
     "duration": 0.032201,
     "end_time": "2025-12-14T11:21:55.328779",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.296578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDs = ProteinDataset(trainDf)\n",
    "valDs   = ProteinDataset(valDf)\n",
    "\n",
    "trainLoader = DataLoader(trainDs, batch_size=4, shuffle=True, collate_fn=collate)\n",
    "valLoader   = DataLoader(valDs,   batch_size=8, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639d369",
   "metadata": {
    "papermill": {
     "duration": 0.007376,
     "end_time": "2025-12-14T11:21:55.343575",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.336199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52603b",
   "metadata": {
    "papermill": {
     "duration": 0.007508,
     "end_time": "2025-12-14T11:21:55.358420",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.350912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional RNN (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6a646a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.374346Z",
     "iopub.status.busy": "2025-12-14T11:21:55.374053Z",
     "iopub.status.idle": "2025-12-14T11:21:55.381146Z",
     "shell.execute_reply": "2025-12-14T11:21:55.380424Z"
    },
    "papermill": {
     "duration": 0.01716,
     "end_time": "2025-12-14T11:21:55.382866",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.365706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiRNN(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.rnn = nn.RNN(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.rnn(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embed_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,\n",
    "        dropout=0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embed_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            nonlinearity=\"tanh\",\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc8 = nn.Linear(hidden_dim * 2, 8)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "\n",
    "        packed = pack_padded_sequence(\n",
    "            x,\n",
    "            lengths.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        packed_out, _ = self.rnn(packed)\n",
    "\n",
    "        h, _ = pad_packed_sequence(\n",
    "            packed_out,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        h = self.norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        p8 = self.fc8(h)\n",
    "        p3 = self.fc3(h)\n",
    "\n",
    "        return p8, p3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99aa3a",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2025-12-14T11:21:55.397512",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.390271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c407f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.413105Z",
     "iopub.status.busy": "2025-12-14T11:21:55.412876Z",
     "iopub.status.idle": "2025-12-14T11:21:55.419267Z",
     "shell.execute_reply": "2025-12-14T11:21:55.418635Z"
    },
    "papermill": {
     "duration": 0.016012,
     "end_time": "2025-12-14T11:21:55.420806",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.404794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiLSTM(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.lstm(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, hidden=256, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed, hidden, num_layers=num_layers, bidirectional=True, \n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0.0)\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc8 = nn.Linear(hidden * 2, 8)\n",
    "        self.fc3 = nn.Linear(hidden * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "\n",
    "        h, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        h = self.norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        out8 = self.fc8(h)\n",
    "        out3 = self.fc3(h)\n",
    "\n",
    "        return out8, out3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3508d4f",
   "metadata": {
    "papermill": {
     "duration": 0.007291,
     "end_time": "2025-12-14T11:21:55.435622",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.428331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Selecting Device (GPU/CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56aa117",
   "metadata": {
    "papermill": {
     "duration": 0.00695,
     "end_time": "2025-12-14T11:21:55.449874",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.442924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking Available Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffdaf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.466080Z",
     "iopub.status.busy": "2025-12-14T11:21:55.465802Z",
     "iopub.status.idle": "2025-12-14T11:21:55.593573Z",
     "shell.execute_reply": "2025-12-14T11:21:55.592340Z"
    },
    "papermill": {
     "duration": 0.138224,
     "end_time": "2025-12-14T11:21:55.595828",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.457604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA GPUs available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU — CPU will be used.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f80d15",
   "metadata": {
    "papermill": {
     "duration": 0.008861,
     "end_time": "2025-12-14T11:21:55.613835",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.604974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selecting GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be0fe5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.689117Z",
     "iopub.status.busy": "2025-12-14T11:21:55.688792Z",
     "iopub.status.idle": "2025-12-14T11:21:55.694239Z",
     "shell.execute_reply": "2025-12-14T11:21:55.693460Z"
    },
    "papermill": {
     "duration": 0.071684,
     "end_time": "2025-12-14T11:21:55.695963",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.624279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bc6c3",
   "metadata": {
    "papermill": {
     "duration": 0.007541,
     "end_time": "2025-12-14T11:21:55.711292",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.703751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function, and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da59b26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.727399Z",
     "iopub.status.busy": "2025-12-14T11:21:55.727055Z",
     "iopub.status.idle": "2025-12-14T11:21:55.731401Z",
     "shell.execute_reply": "2025-12-14T11:21:55.730633Z"
    },
    "papermill": {
     "duration": 0.014289,
     "end_time": "2025-12-14T11:21:55.732943",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.718654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "def harmonic_mean(a, b):\n",
    "    return 2 / (1/a + 1/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6185d9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.749367Z",
     "iopub.status.busy": "2025-12-14T11:21:55.749080Z",
     "iopub.status.idle": "2025-12-14T11:21:55.757018Z",
     "shell.execute_reply": "2025-12-14T11:21:55.756132Z"
    },
    "papermill": {
     "duration": 0.018599,
     "end_time": "2025-12-14T11:21:55.758985",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.740386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataLoader):\n",
    "    model.eval()\n",
    "\n",
    "    all8_true, all8_pred = [], []\n",
    "    all3_true, all3_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, lengths, y8, y3 in dataLoader:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1).view(-1)\n",
    "            pred3 = p3.argmax(dim=-1).view(-1)\n",
    "\n",
    "            y8_flat = y8.view(-1)\n",
    "            y3_flat = y3.view(-1)\n",
    "\n",
    "            mask8 = (y8_flat != -1)\n",
    "            mask3 = (y3_flat != -1)\n",
    "\n",
    "            all8_true.extend(y8_flat[mask8].cpu().tolist())\n",
    "            all8_pred.extend(pred8[mask8].cpu().tolist())\n",
    "\n",
    "            all3_true.extend(y3_flat[mask3].cpu().tolist())\n",
    "            all3_pred.extend(pred3[mask3].cpu().tolist())\n",
    "\n",
    "    f18 = f1_score(all8_true, all8_pred, average=\"macro\")\n",
    "    f13 = f1_score(all3_true, all3_pred, average=\"macro\")\n",
    "    hm = harmonic_mean(f18, f13)\n",
    "\n",
    "    return f18, f13, hm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5fb07",
   "metadata": {
    "papermill": {
     "duration": 0.008782,
     "end_time": "2025-12-14T11:21:55.776485",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.767703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86429f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.795282Z",
     "iopub.status.busy": "2025-12-14T11:21:55.794947Z",
     "iopub.status.idle": "2025-12-14T11:21:55.806350Z",
     "shell.execute_reply": "2025-12-14T11:21:55.805391Z"
    },
    "papermill": {
     "duration": 0.023305,
     "end_time": "2025-12-14T11:21:55.808292",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.784987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    epochs=10,\n",
    "    w8=1.5,   # weight for Q8\n",
    "    w3=1.0    # weight for Q3\n",
    "):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        batch_bar = tqdm(\n",
    "            trainLoader,\n",
    "            desc=f\"Epoch {ep+1}/{epochs}\",\n",
    "            mininterval=0.5\n",
    "        )\n",
    "\n",
    "        total_loss_ep = 0.0\n",
    "        total_loss8_ep = 0.0\n",
    "        total_loss3_ep = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for x, lengths, y8, y3 in batch_bar:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            # flatten for CE loss\n",
    "            loss8 = criterion(p8.view(-1, 8), y8.view(-1))\n",
    "            loss3 = criterion(p3.view(-1, 3), y3.view(-1))\n",
    "\n",
    "            total_loss = w8 * loss8 + w3 * loss3\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_ep += total_loss.item()\n",
    "            total_loss8_ep += loss8.item()\n",
    "            total_loss3_ep += loss3.item()\n",
    "            total_batches += 1\n",
    "\n",
    "            batch_bar.set_postfix({\n",
    "                \"loss8\": f\"{loss8.item():.4f}\",\n",
    "                \"loss3\": f\"{loss3.item():.4f}\",\n",
    "                \"total\": f\"{total_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "        # ---- Validation ----\n",
    "        f18, f13, hm = evaluate(model, valLoader)\n",
    "\n",
    "        avg_loss = total_loss_ep / total_batches\n",
    "        avg_loss8 = total_loss8_ep / total_batches\n",
    "        avg_loss3 = total_loss3_ep / total_batches\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {ep+1} Validation | \"\n",
    "            f\"F1-8={f18:.4f} | F1-3={f13:.4f} | HM={hm:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(hm)\n",
    "\n",
    "        # TrackIO logging (corrected)\n",
    "        trackio.log({\n",
    "            \"epoch\": ep + 1,\n",
    "            \"loss_epoch\": avg_loss,\n",
    "            \"loss8_epoch\": avg_loss8,\n",
    "            \"loss3_epoch\": avg_loss3,\n",
    "            \"val_F1_8\": f18,\n",
    "            \"val_F1_3\": f13,\n",
    "            \"val_harmonic_mean\": hm\n",
    "        })\n",
    "\n",
    "    trackio.finish()\n",
    "    print(\"Training finished & logged to TrackIO.\\n\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbdbbc",
   "metadata": {
    "papermill": {
     "duration": 0.008497,
     "end_time": "2025-12-14T11:21:55.825536",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.817039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d9ee6",
   "metadata": {
    "papermill": {
     "duration": 0.007443,
     "end_time": "2025-12-14T11:21:55.841329",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.833886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Switcher / Control - Training and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd863506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.861083Z",
     "iopub.status.busy": "2025-12-14T11:21:55.860713Z",
     "iopub.status.idle": "2025-12-14T11:21:55.865296Z",
     "shell.execute_reply": "2025-12-14T11:21:55.864228Z"
    },
    "papermill": {
     "duration": 0.017291,
     "end_time": "2025-12-14T11:21:55.867563",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.850272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "canTrain = True\n",
    "canTrainBiRNN = True\n",
    "canTrainBiLSTM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a9441",
   "metadata": {
    "papermill": {
     "duration": 0.008959,
     "end_time": "2025-12-14T11:21:55.886037",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.877078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Trackio Initialization and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f943ea9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.906047Z",
     "iopub.status.busy": "2025-12-14T11:21:55.905679Z",
     "iopub.status.idle": "2025-12-14T11:21:55.914362Z",
     "shell.execute_reply": "2025-12-14T11:21:55.913533Z"
    },
    "papermill": {
     "duration": 0.021288,
     "end_time": "2025-12-14T11:21:55.916567",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.895279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAGGLE_USERNAME = \"vivek0620\"\n",
    "FRAMEWORK = \"pytorch\"\n",
    "\n",
    "def trackioInit(run_name, group, optimizer, batch_size=1, extra_config=None):\n",
    "\n",
    "    # Base config\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "    }\n",
    "\n",
    "    # Merge extra hyperparameters, if provided\n",
    "    if extra_config is not None:\n",
    "        config.update(extra_config)\n",
    "\n",
    "    # Initialize TrackIO\n",
    "    trackio.init(\n",
    "        project=\"25-t3-nppe2\",\n",
    "        space_id=\"bytescode/dlgenai-nppe\",\n",
    "        name=run_name,\n",
    "        group=group,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    print(f\"[TrackIO] Run initialized → {run_name} (Group: {group})\")\n",
    "\n",
    "\n",
    "def get_model_params(model, optimizer):\n",
    "    # ---- Embedding ----\n",
    "    if hasattr(model, \"embedding\"):\n",
    "        embed_dim = model.embedding.embedding_dim\n",
    "    elif hasattr(model, \"emb\"):\n",
    "        embed_dim = model.emb.embedding_dim\n",
    "    else:\n",
    "        embed_dim = None  # e.g. transformer with external embeddings\n",
    "\n",
    "    # ---- Learning rate ----\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # ---- Model type detection ----\n",
    "    if hasattr(model, \"lstm\"):\n",
    "        hidden_dim = model.lstm.hidden_size\n",
    "        layers = model.lstm.num_layers\n",
    "        model_type = \"BiLSTM\"\n",
    "\n",
    "    elif hasattr(model, \"rnn\"):\n",
    "        hidden_dim = model.rnn.hidden_size\n",
    "        layers = model.rnn.num_layers\n",
    "        model_type = \"BiRNN\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported model: expected attribute 'lstm' or 'rnn'\"\n",
    "        )\n",
    "\n",
    "    return model_type, hidden_dim, embed_dim, layers, lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add27689",
   "metadata": {
    "papermill": {
     "duration": 0.008981,
     "end_time": "2025-12-14T11:21:55.934700",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.925719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e1a102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:55.953808Z",
     "iopub.status.busy": "2025-12-14T11:21:55.953027Z",
     "iopub.status.idle": "2025-12-14T11:21:56.065738Z",
     "shell.execute_reply": "2025-12-14T11:21:56.064679Z"
    },
    "papermill": {
     "duration": 0.124924,
     "end_time": "2025-12-14T11:21:56.068382",
     "exception": false,
     "start_time": "2025-12-14T11:21:55.943458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(aa2id) + 1\n",
    "\n",
    "birnn = BiRNN(vocab_size)\n",
    "bilstm = BiLSTM(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a437d8",
   "metadata": {
    "papermill": {
     "duration": 0.009058,
     "end_time": "2025-12-14T11:21:56.086778",
     "exception": false,
     "start_time": "2025-12-14T11:21:56.077720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-RNN & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c4680bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:21:56.107197Z",
     "iopub.status.busy": "2025-12-14T11:21:56.106412Z",
     "iopub.status.idle": "2025-12-14T11:36:31.410674Z",
     "shell.execute_reply": "2025-12-14T11:36:31.409703Z"
    },
    "papermill": {
     "duration": 875.316206,
     "end_time": "2025-12-14T11:36:31.412502",
     "exception": false,
     "start_time": "2025-12-14T11:21:56.096296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiRNN...\n",
      "Run name: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "* Trackio project initialized: 25-t3-nppe2\n",
      "* Trackio metrics will be synced to Hugging Face Dataset: bytescode/dlgenai-nppe-dataset\n",
      "* Found existing space: https://huggingface.co/spaces/bytescode/dlgenai-nppe\n",
      "* View dashboard by going to: https://bytescode-dlgenai-nppe.hf.space/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bytescode-dlgenai-nppe.hf.space/\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Created new run: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiRNN-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11: 100%|██████████| 1634/1634 [01:19<00:00, 20.48it/s, loss8=1.0610, loss3=0.6933, total=2.2848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.2754 | F1-3=0.6553 | HM=0.3878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.37it/s, loss8=1.3245, loss3=0.7837, total=2.7705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.2922 | F1-3=0.6721 | HM=0.4074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11: 100%|██████████| 1634/1634 [01:17<00:00, 20.96it/s, loss8=1.3107, loss3=0.7481, total=2.7141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.2951 | F1-3=0.6824 | HM=0.4120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11: 100%|██████████| 1634/1634 [01:21<00:00, 20.10it/s, loss8=1.2878, loss3=0.7390, total=2.6706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.2937 | F1-3=0.6621 | HM=0.4069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11: 100%|██████████| 1634/1634 [01:19<00:00, 20.47it/s, loss8=1.1989, loss3=0.6780, total=2.4764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3042 | F1-3=0.6891 | HM=0.4221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.29it/s, loss8=1.1614, loss3=0.7593, total=2.5015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.2969 | F1-3=0.6633 | HM=0.4102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.18it/s, loss8=1.0629, loss3=0.5930, total=2.1874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.3074 | F1-3=0.6888 | HM=0.4251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11: 100%|██████████| 1634/1634 [01:19<00:00, 20.58it/s, loss8=1.1561, loss3=0.6508, total=2.3850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3111 | F1-3=0.6888 | HM=0.4286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11: 100%|██████████| 1634/1634 [01:09<00:00, 23.54it/s, loss8=1.2104, loss3=0.7014, total=2.5170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3056 | F1-3=0.6947 | HM=0.4245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11: 100%|██████████| 1634/1634 [01:09<00:00, 23.47it/s, loss8=1.1655, loss3=0.6701, total=2.4183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3115 | F1-3=0.6908 | HM=0.4294\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11: 100%|██████████| 1634/1634 [01:09<00:00, 23.61it/s, loss8=1.2885, loss3=0.7973, total=2.7300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3122 | F1-3=0.6894 | HM=0.4298\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiRNN-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiRNN:\n",
    "    print(\"Training BiRNN...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(birnn.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 11\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        birnn, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "\n",
    "    birnn_model = train_model(model=birnn, optimizer=optimizer, criterion=criterion, \n",
    "                              scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(birnn_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping BiRNN training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a511e54",
   "metadata": {
    "papermill": {
     "duration": 0.874682,
     "end_time": "2025-12-14T11:36:33.219462",
     "exception": false,
     "start_time": "2025-12-14T11:36:32.344780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-LSTM & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b613e2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:36:35.068198Z",
     "iopub.status.busy": "2025-12-14T11:36:35.067623Z",
     "iopub.status.idle": "2025-12-14T11:58:25.958513Z",
     "shell.execute_reply": "2025-12-14T11:58:25.957563Z"
    },
    "papermill": {
     "duration": 1311.815901,
     "end_time": "2025-12-14T11:58:25.960369",
     "exception": false,
     "start_time": "2025-12-14T11:36:34.144468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM...\n",
      "Run name: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "* Created new run: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiLSTM-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/17: 100%|██████████| 1634/1634 [01:16<00:00, 21.24it/s, loss8=1.0575, loss3=0.6304, total=2.2167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.2842 | F1-3=0.6663 | HM=0.3984\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/17: 100%|██████████| 1634/1634 [01:15<00:00, 21.53it/s, loss8=1.3375, loss3=0.7978, total=2.8039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.2992 | F1-3=0.6918 | HM=0.4177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/17: 100%|██████████| 1634/1634 [01:15<00:00, 21.74it/s, loss8=1.0808, loss3=0.6048, total=2.2259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.3150 | F1-3=0.6983 | HM=0.4342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/17: 100%|██████████| 1634/1634 [01:15<00:00, 21.65it/s, loss8=1.0552, loss3=0.6254, total=2.2082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.3155 | F1-3=0.7052 | HM=0.4359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.96it/s, loss8=0.8664, loss3=0.4669, total=1.7665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3189 | F1-3=0.6991 | HM=0.4380\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/17: 100%|██████████| 1634/1634 [01:15<00:00, 21.51it/s, loss8=1.0561, loss3=0.5992, total=2.1834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.3194 | F1-3=0.7049 | HM=0.4396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/17: 100%|██████████| 1634/1634 [01:15<00:00, 21.78it/s, loss8=1.0350, loss3=0.5558, total=2.1083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.3268 | F1-3=0.7072 | HM=0.4471\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.91it/s, loss8=0.7393, loss3=0.4079, total=1.5169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3244 | F1-3=0.7058 | HM=0.4445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.91it/s, loss8=0.8596, loss3=0.5006, total=1.7901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3243 | F1-3=0.7076 | HM=0.4448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.92it/s, loss8=0.8356, loss3=0.4569, total=1.7102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3289 | F1-3=0.7051 | HM=0.4485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/17: 100%|██████████| 1634/1634 [01:13<00:00, 22.16it/s, loss8=0.9049, loss3=0.4844, total=1.8417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3306 | F1-3=0.6982 | HM=0.4487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.86it/s, loss8=0.9196, loss3=0.4355, total=1.8150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation | F1-8=0.3249 | F1-3=0.7025 | HM=0.4443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/17: 100%|██████████| 1634/1634 [01:14<00:00, 22.00it/s, loss8=1.0210, loss3=0.6096, total=2.1411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation | F1-8=0.3253 | F1-3=0.6966 | HM=0.4435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.84it/s, loss8=0.8062, loss3=0.4638, total=1.6730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation | F1-8=0.3251 | F1-3=0.6980 | HM=0.4436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.94it/s, loss8=1.0895, loss3=0.5933, total=2.2275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation | F1-8=0.3294 | F1-3=0.6962 | HM=0.4472\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.98it/s, loss8=0.8005, loss3=0.4096, total=1.6104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation | F1-8=0.3268 | F1-3=0.6938 | HM=0.4443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/17: 100%|██████████| 1634/1634 [01:14<00:00, 21.96it/s, loss8=0.8604, loss3=0.4323, total=1.7230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation | F1-8=0.3273 | F1-3=0.6933 | HM=0.4447\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiLSTM-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiLSTM:\n",
    "    print(\"Training BiLSTM...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(bilstm.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 17\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        bilstm, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "    model = bilstm\n",
    "    bilstm_model = train_model(model=bilstm, optimizer=optimizer, criterion=criterion,\n",
    "        scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(bilstm_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107a31d",
   "metadata": {
    "papermill": {
     "duration": 2.284233,
     "end_time": "2025-12-14T11:58:30.655843",
     "exception": false,
     "start_time": "2025-12-14T11:58:28.371610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554f28f",
   "metadata": {
    "papermill": {
     "duration": 2.287921,
     "end_time": "2025-12-14T11:58:35.309162",
     "exception": false,
     "start_time": "2025-12-14T11:58:33.021241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9c5eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:58:40.012153Z",
     "iopub.status.busy": "2025-12-14T11:58:40.011852Z",
     "iopub.status.idle": "2025-12-14T11:58:44.051834Z",
     "shell.execute_reply": "2025-12-14T11:58:44.050840Z"
    },
    "papermill": {
     "duration": 6.42003,
     "end_time": "2025-12-14T11:58:44.053617",
     "exception": false,
     "start_time": "2025-12-14T11:58:37.633587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL COMPARISON ===\n",
      "\n",
      "BiRNN  → F1-8=0.3122 | F1-3=0.6894 | HM=0.4298\n",
      "BiLSTM → F1-8=0.3273 | F1-3=0.6933 | HM=0.4447\n",
      "\n",
      ">>> BiLSTM is better overall.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MODEL COMPARISON ===\\n\")\n",
    "\n",
    "birnn_f18, birnn_f13, birnn_hm = evaluate(birnn_model, valLoader)\n",
    "bilstm_f18, bilstm_f13, bilstm_hm = evaluate(bilstm_model, valLoader)\n",
    "\n",
    "print(f\"BiRNN  → F1-8={birnn_f18:.4f} | F1-3={birnn_f13:.4f} | HM={birnn_hm:.4f}\")\n",
    "print(f\"BiLSTM → F1-8={bilstm_f18:.4f} | F1-3={bilstm_f13:.4f} | HM={bilstm_hm:.4f}\")\n",
    "\n",
    "if bilstm_hm > birnn_hm:\n",
    "    print(\"\\n>>> BiLSTM is better overall.\")\n",
    "else:\n",
    "    print(\"\\n>>> BiRNN is better overall.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cbc71",
   "metadata": {
    "papermill": {
     "duration": 2.390581,
     "end_time": "2025-12-14T11:58:48.786236",
     "exception": false,
     "start_time": "2025-12-14T11:58:46.395655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selection Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2fefafd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:58:53.405803Z",
     "iopub.status.busy": "2025-12-14T11:58:53.405446Z",
     "iopub.status.idle": "2025-12-14T11:58:53.410508Z",
     "shell.execute_reply": "2025-12-14T11:58:53.409632Z"
    },
    "papermill": {
     "duration": 2.35005,
     "end_time": "2025-12-14T11:58:53.412704",
     "exception": false,
     "start_time": "2025-12-14T11:58:51.062654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Best model selected: BiLSTM\n"
     ]
    }
   ],
   "source": [
    "if bilstm_hm > birnn_hm:\n",
    "    best_model = bilstm_model\n",
    "    best_name = \"BiLSTM\"\n",
    "else:\n",
    "    best_model = birnn_model\n",
    "    best_name = \"BiRNN\"\n",
    "\n",
    "print(f\"\\n>>> Best model selected: {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8b38e",
   "metadata": {
    "papermill": {
     "duration": 2.303847,
     "end_time": "2025-12-14T11:58:58.100101",
     "exception": false,
     "start_time": "2025-12-14T11:58:55.796254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dac64f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:59:02.716293Z",
     "iopub.status.busy": "2025-12-14T11:59:02.715981Z",
     "iopub.status.idle": "2025-12-14T11:59:02.722502Z",
     "shell.execute_reply": "2025-12-14T11:59:02.721777Z"
    },
    "papermill": {
     "duration": 2.277748,
     "end_time": "2025-12-14T11:59:02.724101",
     "exception": false,
     "start_time": "2025-12-14T11:59:00.446353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    model.eval()\n",
    "\n",
    "    seqs8, seqs3 = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq in df[\"seq\"]:\n",
    "            # Clean sequence (important!)\n",
    "            seq = re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "            # Encode\n",
    "            x = torch.tensor(\n",
    "                [aa2id.get(a, aa2id[\"X\"]) for a in seq],\n",
    "                dtype=torch.long\n",
    "            ).unsqueeze(0).to(device)\n",
    "\n",
    "            lengths = torch.tensor([len(seq)], dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1)[0].tolist()\n",
    "            pred3 = p3.argmax(dim=-1)[0].tolist()\n",
    "\n",
    "            # Decode → characters\n",
    "            s8 = \"\".join(id2sst8[i] for i in pred8)\n",
    "            s3 = \"\".join(id2sst3[i] for i in pred3)\n",
    "\n",
    "            seqs8.append(s8)\n",
    "            seqs3.append(s3)\n",
    "\n",
    "    return seqs8, seqs3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c510b",
   "metadata": {
    "papermill": {
     "duration": 2.355684,
     "end_time": "2025-12-14T11:59:07.417030",
     "exception": false,
     "start_time": "2025-12-14T11:59:05.061346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict (sst8 & sst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e58c23b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:59:12.050280Z",
     "iopub.status.busy": "2025-12-14T11:59:12.049972Z",
     "iopub.status.idle": "2025-12-14T11:59:28.329714Z",
     "shell.execute_reply": "2025-12-14T11:59:28.328804Z"
    },
    "papermill": {
     "duration": 18.618537,
     "end_time": "2025-12-14T11:59:28.331700",
     "exception": false,
     "start_time": "2025-12-14T11:59:09.713163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_s8, test_s3 = predict(best_model, testDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f11ac5",
   "metadata": {
    "papermill": {
     "duration": 2.331878,
     "end_time": "2025-12-14T11:59:32.939664",
     "exception": false,
     "start_time": "2025-12-14T11:59:30.607786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6c0c8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:59:37.596085Z",
     "iopub.status.busy": "2025-12-14T11:59:37.595532Z",
     "iopub.status.idle": "2025-12-14T11:59:37.632704Z",
     "shell.execute_reply": "2025-12-14T11:59:37.631881Z"
    },
    "papermill": {
     "duration": 2.417611,
     "end_time": "2025-12-14T11:59:37.634355",
     "exception": false,
     "start_time": "2025-12-14T11:59:35.216744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCCTHHHHHHHHHHHHHHHHHHHCSEEEEEECCCTTCCEEEEEECC...</td>\n",
       "      <td>CCCCHHHHHHHHHHHHHHHHHHHCCEEEEEECCCCCCCCEEEEECC...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CCCCCCCCCCCEEEEEECSTTCEEEEEECTTCEEEEEESCCEETGG...</td>\n",
       "      <td>CCCCCCCCCCCEEEEEECCCCCEEEEECCCCCEEEEECCCCCCCHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CCHHHHHHHHHHHHHHHHHCTHHHHHHHHHHHCCCCSHTHHHHHHH...</td>\n",
       "      <td>CCHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHCCCCCCCHHHHHHH...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CCCTHHHHHHHHHHHHHHHHHHHHHHHHCCEEEEESEHHHHHHHHH...</td>\n",
       "      <td>CCCCHHHHHHHHHHHHHHHHHHHHHHHHCCEEEECCCEHHHHCCHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CEEEEEEECCCTHHHHHHHHHHHHHHHCCEEEECTTTCEEEEEEEE...</td>\n",
       "      <td>CEEEEEEECCCCHHHHHHHHHHHHHHHCCCCECCCCCCEEEECCEE...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               sst8  \\\n",
       "0   0  CCCTHHHHHHHHHHHHHHHHHHHCSEEEEEECCCTTCCEEEEEECC...   \n",
       "1   1  CCCCCCCCCCCEEEEEECSTTCEEEEEECTTCEEEEEESCCEETGG...   \n",
       "2   2  CCHHHHHHHHHHHHHHHHHCTHHHHHHHHHHHCCCCSHTHHHHHHH...   \n",
       "3   3  CCCTHHHHHHHHHHHHHHHHHHHHHHHHCCEEEEESEHHHHHHHHH...   \n",
       "4   4  CEEEEEEECCCTHHHHHHHHHHHHHHHCCEEEECTTTCEEEEEEEE...   \n",
       "\n",
       "                                                sst3    Usage  \n",
       "0  CCCCHHHHHHHHHHHHHHHHHHHCCEEEEEECCCCCCCCEEEEECC...  Private  \n",
       "1  CCCCCCCCCCCEEEEEECCCCCEEEEECCCCCEEEEECCCCCCCHH...  Private  \n",
       "2  CCHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHCCCCCCCHHHHHHH...   Public  \n",
       "3  CCCCHHHHHHHHHHHHHHHHHHHHHHHHCCEEEECCCEHHHHCCHH...  Private  \n",
       "4  CEEEEEEECCCCHHHHHHHHHHHHHHHCCCCECCCCCCEEEECCEE...  Private  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sampleDf.copy()\n",
    "\n",
    "submission[\"sst8\"] = test_s8\n",
    "submission[\"sst3\"] = test_s3\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv\\n\")\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14858151,
     "sourceId": 125543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2358.217367,
   "end_time": "2025-12-14T11:59:42.774208",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T11:20:24.556841",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
