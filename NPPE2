{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e958dc5",
   "metadata": {
    "papermill": {
     "duration": 0.009081,
     "end_time": "2025-12-14T10:47:40.595023",
     "exception": false,
     "start_time": "2025-12-14T10:47:40.585942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d074a8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:47:40.613959Z",
     "iopub.status.busy": "2025-12-14T10:47:40.613595Z",
     "iopub.status.idle": "2025-12-14T10:48:51.493954Z",
     "shell.execute_reply": "2025-12-14T10:48:51.492646Z"
    },
    "papermill": {
     "duration": 70.900592,
     "end_time": "2025-12-14T10:48:51.504422",
     "exception": false,
     "start_time": "2025-12-14T10:47:40.603830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trackio -qqq > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da188597",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T10:48:51.523099Z",
     "iopub.status.busy": "2025-12-14T10:48:51.522455Z",
     "iopub.status.idle": "2025-12-14T10:49:06.487912Z",
     "shell.execute_reply": "2025-12-14T10:49:06.486811Z"
    },
    "papermill": {
     "duration": 14.977465,
     "end_time": "2025-12-14T10:49:06.490128",
     "exception": false,
     "start_time": "2025-12-14T10:48:51.512663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Imports Done, Good to go....\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trackio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import subprocess\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import kagglehub\n",
    "\n",
    "print(\"All Imports Done, Good to go....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c0bd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:06.510616Z",
     "iopub.status.busy": "2025-12-14T10:49:06.509616Z",
     "iopub.status.idle": "2025-12-14T10:49:06.811502Z",
     "shell.execute_reply": "2025-12-14T10:49:06.810365Z"
    },
    "papermill": {
     "duration": 0.313786,
     "end_time": "2025-12-14T10:49:06.813788",
     "exception": false,
     "start_time": "2025-12-14T10:49:06.500002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Hub authenticated as: vivek0620\n"
     ]
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# ---- Hugging Face ----\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "# ---- Kaggle ----\n",
    "api_token = user_secrets.get_secret(\"KAGGLE_JSON\")\n",
    "json.loads(api_token)  # validate JSON\n",
    "\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(api_token)\n",
    "\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/root/.kaggle\"\n",
    "\n",
    "print(\"Kaggle Hub authenticated as:\", kagglehub.whoami()[\"username\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9454c4",
   "metadata": {
    "papermill": {
     "duration": 0.008091,
     "end_time": "2025-12-14T10:49:06.830642",
     "exception": false,
     "start_time": "2025-12-14T10:49:06.822551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30792459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:06.850914Z",
     "iopub.status.busy": "2025-12-14T10:49:06.850125Z",
     "iopub.status.idle": "2025-12-14T10:49:07.035808Z",
     "shell.execute_reply": "2025-12-14T10:49:07.034854Z"
    },
    "papermill": {
     "duration": 0.197837,
     "end_time": "2025-12-14T10:49:07.038645",
     "exception": false,
     "start_time": "2025-12-14T10:49:06.840808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6535\n",
      "Val samples: 727\n",
      "Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "sampleSumbPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/sample_submission.csv'\n",
    "trainingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/train.csv'\n",
    "testingDataPath = '/kaggle/input/sep-25-dl-gen-ai-nppe-2/test.csv'\n",
    "\n",
    "trainDf = pd.read_csv(trainingDataPath)\n",
    "testDf = pd.read_csv(testingDataPath)\n",
    "sampleDf = pd.read_csv(sampleSumbPath)\n",
    "\n",
    "trainDf, valDf = train_test_split(trainDf, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train samples:\", len(trainDf))\n",
    "print(\"Val samples:\", len(valDf))\n",
    "\n",
    "\n",
    "print(\"Data Loaded Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c3a62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.059821Z",
     "iopub.status.busy": "2025-12-14T10:49:07.059441Z",
     "iopub.status.idle": "2025-12-14T10:49:07.078223Z",
     "shell.execute_reply": "2025-12-14T10:49:07.077197Z"
    },
    "papermill": {
     "duration": 0.031755,
     "end_time": "2025-12-14T10:49:07.080231",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.048476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071</td>\n",
       "      <td>WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...</td>\n",
       "      <td>CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "      <td>CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...</td>\n",
       "      <td>CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...</td>\n",
       "      <td>CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...</td>\n",
       "      <td>CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...</td>\n",
       "      <td>CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                seq  \\\n",
       "3071  3071  WFDPLSYRYTNTRHWDHNGDVWAAVGRLFRLVPPLPCAEALDAAAA...   \n",
       "1699  1699  HYRPCDASQGTCRDDPMDGRPIRCITRKKKFKCQECCLGEGCQAGP...   \n",
       "592    592  VLPGWFVKNTSDGDNMFFDSGAIVFEELSLLGDNNTDIADFSAPAM...   \n",
       "\n",
       "                                                   sst8  \\\n",
       "3071  CCSCCCCTTTCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...   \n",
       "1699  CCSCCSSCSSCCEECBCSSSCCEEECTTCCEETTEETTSSSCCCTT...   \n",
       "592   CCSSTTGGGGCCSSCHHHHHHHHHHHHHEECSSCTTCHHHHHHHHS...   \n",
       "\n",
       "                                                   sst3  \n",
       "3071  CCCCCCCCCCCHHHHHHHHHHHHHHHHHHHHHHHCCCHHHHHHHHH...  \n",
       "1699  CCCCCCCCCCCCEECECCCCCCEEECCCCCEECCEECCCCCCCCCC...  \n",
       "592   CCCCCCHHHHCCCCCHHHHHHHHHHHHHEECCCCCCCHHHHHHHHC...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Data....\\n\")\n",
    "trainDf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81cd5ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.100080Z",
     "iopub.status.busy": "2025-12-14T10:49:07.099141Z",
     "iopub.status.idle": "2025-12-14T10:49:07.109601Z",
     "shell.execute_reply": "2025-12-14T10:49:07.108530Z"
    },
    "papermill": {
     "duration": 0.022348,
     "end_time": "2025-12-14T10:49:07.111499",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.089151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                seq\n",
       "0   0  FFKGSYQKVSNQLLYQANQIQDQTGTITIIRDESGELPEDIKISAG...\n",
       "1   1  ATTKKNSPFPKVEEAYVSGDANITLFIKRGAHIAQNISSPYVGLDK...\n",
       "2   2  VRALMLELRSGVREALDALGGVWEITKYLFMVDVPNLESELAFLQR..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing data....\\n\")\n",
    "testDf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3795ca",
   "metadata": {
    "papermill": {
     "duration": 0.00883,
     "end_time": "2025-12-14T10:49:07.129339",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.120509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85cb2fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.149228Z",
     "iopub.status.busy": "2025-12-14T10:49:07.148225Z",
     "iopub.status.idle": "2025-12-14T10:49:07.155222Z",
     "shell.execute_reply": "2025-12-14T10:49:07.154250Z"
    },
    "papermill": {
     "duration": 0.019176,
     "end_time": "2025-12-14T10:49:07.157183",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.138007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 20 standard AAs + X (unknown)\n",
    "AAs = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "aa2id = {a: i + 1 for i, a in enumerate(AAs)}\n",
    "aa2id[\"X\"] = len(aa2id) + 1  # unknown / masked\n",
    "id2aa = {i: a for a, i in aa2id.items()}\n",
    "\n",
    "# Q8 labels (DSSP)\n",
    "sst8_chars = list(\"CHES TBIG\".replace(\" \", \"\"))  # C H E S T B I G\n",
    "sst8_map = {c: i for i, c in enumerate(sst8_chars)}\n",
    "id2sst8 = {i: c for c, i in sst8_map.items()}\n",
    "\n",
    "# Q3 labels\n",
    "sst3_chars = list(\"CHE\")  # C=coil, H=helix, E=strand\n",
    "sst3_map = {c: i for i, c in enumerate(sst3_chars)}\n",
    "id2sst3 = {i: c for c, i in sst3_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6fe06",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2025-12-14T10:49:07.174826",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.166334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5799a7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.194261Z",
     "iopub.status.busy": "2025-12-14T10:49:07.193913Z",
     "iopub.status.idle": "2025-12-14T10:49:07.204715Z",
     "shell.execute_reply": "2025-12-14T10:49:07.203718Z"
    },
    "papermill": {
     "duration": 0.022984,
     "end_time": "2025-12-14T10:49:07.206690",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.183706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_sequence(seq):\n",
    "    return re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Clean sequences\n",
    "        self.seq = [clean_sequence(s) for s in df[\"seq\"].tolist()]\n",
    "        self.s8  = df[\"sst8\"].tolist()\n",
    "        self.s3  = df[\"sst3\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Amino acid encoding\n",
    "        x = torch.tensor(\n",
    "            [aa2id.get(a, aa2id[\"X\"]) for a in self.seq[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q8 labels\n",
    "        y8 = torch.tensor(\n",
    "            [sst8_map[c] for c in self.s8[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Q3 labels\n",
    "        y3 = torch.tensor(\n",
    "            [sst3_map[c] for c in self.s3[idx]],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return x, y8, y3\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    xs, y8s, y3s = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "\n",
    "    xs  = pad_sequence(xs,  batch_first=True, padding_value=0)\n",
    "    y8s = pad_sequence(y8s, batch_first=True, padding_value=-1)\n",
    "    y3s = pad_sequence(y3s, batch_first=True, padding_value=-1)\n",
    "\n",
    "    return xs, lengths, y8s, y3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72783a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.226578Z",
     "iopub.status.busy": "2025-12-14T10:49:07.225914Z",
     "iopub.status.idle": "2025-12-14T10:49:07.252138Z",
     "shell.execute_reply": "2025-12-14T10:49:07.251158Z"
    },
    "papermill": {
     "duration": 0.038391,
     "end_time": "2025-12-14T10:49:07.254119",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.215728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDs = ProteinDataset(trainDf)\n",
    "valDs   = ProteinDataset(valDf)\n",
    "\n",
    "trainLoader = DataLoader(trainDs, batch_size=4, shuffle=True, collate_fn=collate)\n",
    "valLoader   = DataLoader(valDs,   batch_size=8, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f9799",
   "metadata": {
    "papermill": {
     "duration": 0.008737,
     "end_time": "2025-12-14T10:49:07.271861",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.263124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234dde8d",
   "metadata": {
    "papermill": {
     "duration": 0.008552,
     "end_time": "2025-12-14T10:49:07.289115",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.280563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional RNN (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad040ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.308625Z",
     "iopub.status.busy": "2025-12-14T10:49:07.307891Z",
     "iopub.status.idle": "2025-12-14T10:49:07.316380Z",
     "shell.execute_reply": "2025-12-14T10:49:07.315470Z"
    },
    "papermill": {
     "duration": 0.020411,
     "end_time": "2025-12-14T10:49:07.318385",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.297974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiRNN(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.rnn = nn.RNN(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.rnn(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embed_dim=128,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,\n",
    "        dropout=0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embed_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            nonlinearity=\"tanh\",\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc8 = nn.Linear(hidden_dim * 2, 8)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "\n",
    "        packed = pack_padded_sequence(\n",
    "            x,\n",
    "            lengths.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        packed_out, _ = self.rnn(packed)\n",
    "\n",
    "        h, _ = pad_packed_sequence(\n",
    "            packed_out,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        h = self.norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        p8 = self.fc8(h)\n",
    "        p3 = self.fc3(h)\n",
    "\n",
    "        return p8, p3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217fd5c2",
   "metadata": {
    "papermill": {
     "duration": 0.008731,
     "end_time": "2025-12-14T10:49:07.336075",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.327344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM (Scratch Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b98b1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.355269Z",
     "iopub.status.busy": "2025-12-14T10:49:07.354923Z",
     "iopub.status.idle": "2025-12-14T10:49:07.367416Z",
     "shell.execute_reply": "2025-12-14T10:49:07.366721Z"
    },
    "papermill": {
     "duration": 0.024402,
     "end_time": "2025-12-14T10:49:07.369279",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.344877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BiLSTM(nn.Module):\n",
    "#     def __init__(self, vocab, embed=64, hidden=128):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(vocab, embed, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(embed, hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc8 = nn.Linear(hidden*2, 8)\n",
    "#         self.fc3 = nn.Linear(hidden*2, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         h, _ = self.lstm(x)\n",
    "#         return self.fc8(h), self.fc3(h)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, hidden=256, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Embedding ----\n",
    "        self.embedding = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "\n",
    "        # ---- BiLSTM ----\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed,\n",
    "            hidden,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # ---- Projection for residual ----\n",
    "        self.res_proj = nn.Linear(embed, hidden * 2)\n",
    "\n",
    "        # ---- Shared normalization ----\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "\n",
    "        # =====================================================\n",
    "        # SST8 ENHANCEMENTS\n",
    "        # =====================================================\n",
    "\n",
    "        # 1️⃣ Channel-wise attention (SE-style)\n",
    "        self.q8_attn = nn.Sequential(\n",
    "            nn.Linear(hidden * 2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden * 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 2️⃣ Gated context selection\n",
    "        self.q8_gate = nn.Linear(hidden * 2, hidden * 2)\n",
    "\n",
    "        # 3️⃣ Strong multi-layer head (acts like ensemble)\n",
    "        self.fc8 = nn.Sequential(\n",
    "            nn.Linear(hidden * 2, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout + 0.15),\n",
    "            nn.Linear(hidden, hidden // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout + 0.1),\n",
    "            nn.Linear(hidden // 2, 8)\n",
    "        )\n",
    "\n",
    "        # 4️⃣ Temperature scaling (learned)\n",
    "        self.q8_temp = nn.Parameter(torch.tensor(1.2))\n",
    "\n",
    "        # =====================================================\n",
    "        # SST3 (keep simple)\n",
    "        # =====================================================\n",
    "        self.fc3 = nn.Linear(hidden * 2, 3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # ---- Embedding ----\n",
    "        emb = self.embedding(x)\n",
    "\n",
    "        # ---- BiLSTM with packing ----\n",
    "        packed = pack_padded_sequence(\n",
    "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        h, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        # ---- Residual connection ----\n",
    "        h = h + self.res_proj(emb)\n",
    "\n",
    "        # ---- Normalize ----\n",
    "        h = self.norm(h)\n",
    "\n",
    "        # =====================================================\n",
    "        # SST8 PATH\n",
    "        # =====================================================\n",
    "\n",
    "        # Channel attention\n",
    "        attn = self.q8_attn(h)\n",
    "        h8 = h * attn\n",
    "\n",
    "        # Context gating\n",
    "        h8 = h8 * torch.sigmoid(self.q8_gate(h8))\n",
    "\n",
    "        # Classification\n",
    "        out8 = self.fc8(h8)\n",
    "\n",
    "        # Temperature scaling (helps rare classes)\n",
    "        out8 = out8 / self.q8_temp\n",
    "\n",
    "        # =====================================================\n",
    "        # SST3 PATH\n",
    "        # =====================================================\n",
    "        out3 = self.fc3(h)\n",
    "\n",
    "        return out8, out3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53477d5b",
   "metadata": {
    "papermill": {
     "duration": 0.008392,
     "end_time": "2025-12-14T10:49:07.386562",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.378170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Selecting Device (GPU/CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ea7b8",
   "metadata": {
    "papermill": {
     "duration": 0.008045,
     "end_time": "2025-12-14T10:49:07.403195",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.395150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking Available Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4647462f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.421675Z",
     "iopub.status.busy": "2025-12-14T10:49:07.421263Z",
     "iopub.status.idle": "2025-12-14T10:49:07.545618Z",
     "shell.execute_reply": "2025-12-14T10:49:07.544564Z"
    },
    "papermill": {
     "duration": 0.13626,
     "end_time": "2025-12-14T10:49:07.547866",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.411606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA GPUs available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU — CPU will be used.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7706d",
   "metadata": {
    "papermill": {
     "duration": 0.008431,
     "end_time": "2025-12-14T10:49:07.565657",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.557226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selecting GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936db445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.645822Z",
     "iopub.status.busy": "2025-12-14T10:49:07.644909Z",
     "iopub.status.idle": "2025-12-14T10:49:07.651555Z",
     "shell.execute_reply": "2025-12-14T10:49:07.650481Z"
    },
    "papermill": {
     "duration": 0.079583,
     "end_time": "2025-12-14T10:49:07.653833",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.574250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ded85d",
   "metadata": {
    "papermill": {
     "duration": 0.008525,
     "end_time": "2025-12-14T10:49:07.671553",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.663028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function, and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd68910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.690738Z",
     "iopub.status.busy": "2025-12-14T10:49:07.690337Z",
     "iopub.status.idle": "2025-12-14T10:49:07.695359Z",
     "shell.execute_reply": "2025-12-14T10:49:07.694364Z"
    },
    "papermill": {
     "duration": 0.01726,
     "end_time": "2025-12-14T10:49:07.697420",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.680160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "def harmonic_mean(a, b):\n",
    "    return 2 / (1/a + 1/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1376a803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.717986Z",
     "iopub.status.busy": "2025-12-14T10:49:07.717607Z",
     "iopub.status.idle": "2025-12-14T10:49:07.726246Z",
     "shell.execute_reply": "2025-12-14T10:49:07.725243Z"
    },
    "papermill": {
     "duration": 0.02136,
     "end_time": "2025-12-14T10:49:07.728195",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.706835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataLoader):\n",
    "    model.eval()\n",
    "\n",
    "    all8_true, all8_pred = [], []\n",
    "    all3_true, all3_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, lengths, y8, y3 in dataLoader:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1).view(-1)\n",
    "            pred3 = p3.argmax(dim=-1).view(-1)\n",
    "\n",
    "            y8_flat = y8.view(-1)\n",
    "            y3_flat = y3.view(-1)\n",
    "\n",
    "            mask8 = (y8_flat != -1)\n",
    "            mask3 = (y3_flat != -1)\n",
    "\n",
    "            all8_true.extend(y8_flat[mask8].cpu().tolist())\n",
    "            all8_pred.extend(pred8[mask8].cpu().tolist())\n",
    "\n",
    "            all3_true.extend(y3_flat[mask3].cpu().tolist())\n",
    "            all3_pred.extend(pred3[mask3].cpu().tolist())\n",
    "\n",
    "    f18 = f1_score(all8_true, all8_pred, average=\"macro\")\n",
    "    f13 = f1_score(all3_true, all3_pred, average=\"macro\")\n",
    "    hm = harmonic_mean(f18, f13)\n",
    "\n",
    "    return f18, f13, hm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0496ef1",
   "metadata": {
    "papermill": {
     "duration": 0.008861,
     "end_time": "2025-12-14T10:49:07.747013",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.738152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5ce2a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.767508Z",
     "iopub.status.busy": "2025-12-14T10:49:07.766512Z",
     "iopub.status.idle": "2025-12-14T10:49:07.777963Z",
     "shell.execute_reply": "2025-12-14T10:49:07.777005Z"
    },
    "papermill": {
     "duration": 0.023924,
     "end_time": "2025-12-14T10:49:07.780003",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.756079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    epochs=10,\n",
    "    w8=1.5,   # weight for Q8\n",
    "    w3=1.0    # weight for Q3\n",
    "):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        batch_bar = tqdm(\n",
    "            trainLoader,\n",
    "            desc=f\"Epoch {ep+1}/{epochs}\",\n",
    "            mininterval=0.5\n",
    "        )\n",
    "\n",
    "        total_loss_ep = 0.0\n",
    "        total_loss8_ep = 0.0\n",
    "        total_loss3_ep = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for x, lengths, y8, y3 in batch_bar:\n",
    "            x = x.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            y8 = y8.to(device)\n",
    "            y3 = y3.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            # flatten for CE loss\n",
    "            loss8 = criterion(p8.view(-1, 8), y8.view(-1))\n",
    "            loss3 = criterion(p3.view(-1, 3), y3.view(-1))\n",
    "\n",
    "            total_loss = w8 * loss8 + w3 * loss3\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_ep += total_loss.item()\n",
    "            total_loss8_ep += loss8.item()\n",
    "            total_loss3_ep += loss3.item()\n",
    "            total_batches += 1\n",
    "\n",
    "            batch_bar.set_postfix({\n",
    "                \"loss8\": f\"{loss8.item():.4f}\",\n",
    "                \"loss3\": f\"{loss3.item():.4f}\",\n",
    "                \"total\": f\"{total_loss.item():.4f}\"\n",
    "            })\n",
    "\n",
    "        # ---- Validation ----\n",
    "        f18, f13, hm = evaluate(model, valLoader)\n",
    "\n",
    "        avg_loss = total_loss_ep / total_batches\n",
    "        avg_loss8 = total_loss8_ep / total_batches\n",
    "        avg_loss3 = total_loss3_ep / total_batches\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {ep+1} Validation | \"\n",
    "            f\"F1-8={f18:.4f} | F1-3={f13:.4f} | HM={hm:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(hm)\n",
    "\n",
    "        # TrackIO logging (corrected)\n",
    "        trackio.log({\n",
    "            \"epoch\": ep + 1,\n",
    "            \"loss_epoch\": avg_loss,\n",
    "            \"loss8_epoch\": avg_loss8,\n",
    "            \"loss3_epoch\": avg_loss3,\n",
    "            \"val_F1_8\": f18,\n",
    "            \"val_F1_3\": f13,\n",
    "            \"val_harmonic_mean\": hm\n",
    "        })\n",
    "\n",
    "    trackio.finish()\n",
    "    print(\"Training finished & logged to TrackIO.\\n\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a631c8",
   "metadata": {
    "papermill": {
     "duration": 0.008734,
     "end_time": "2025-12-14T10:49:07.798154",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.789420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f695c",
   "metadata": {
    "papermill": {
     "duration": 0.008637,
     "end_time": "2025-12-14T10:49:07.815738",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.807101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Switcher / Control - Training and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15a6cff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.835196Z",
     "iopub.status.busy": "2025-12-14T10:49:07.834787Z",
     "iopub.status.idle": "2025-12-14T10:49:07.840262Z",
     "shell.execute_reply": "2025-12-14T10:49:07.839389Z"
    },
    "papermill": {
     "duration": 0.017541,
     "end_time": "2025-12-14T10:49:07.842154",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.824613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "canTrain = True\n",
    "canTrainBiRNN = True\n",
    "canTrainBiLSTM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10893da",
   "metadata": {
    "papermill": {
     "duration": 0.008615,
     "end_time": "2025-12-14T10:49:07.859999",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.851384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Trackio Initialization and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b248cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.880334Z",
     "iopub.status.busy": "2025-12-14T10:49:07.879586Z",
     "iopub.status.idle": "2025-12-14T10:49:07.888080Z",
     "shell.execute_reply": "2025-12-14T10:49:07.887158Z"
    },
    "papermill": {
     "duration": 0.02115,
     "end_time": "2025-12-14T10:49:07.890018",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.868868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAGGLE_USERNAME = \"vivek0620\"\n",
    "FRAMEWORK = \"pytorch\"\n",
    "\n",
    "def trackioInit(run_name, group, optimizer, batch_size=1, extra_config=None):\n",
    "\n",
    "    # Base config\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "    }\n",
    "\n",
    "    # Merge extra hyperparameters, if provided\n",
    "    if extra_config is not None:\n",
    "        config.update(extra_config)\n",
    "\n",
    "    # Initialize TrackIO\n",
    "    trackio.init(\n",
    "        project=\"25-t3-nppe2\",\n",
    "        space_id=\"bytescode/dlgenai-nppe\",\n",
    "        name=run_name,\n",
    "        group=group,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    print(f\"[TrackIO] Run initialized → {run_name} (Group: {group})\")\n",
    "\n",
    "\n",
    "def get_model_params(model, optimizer):\n",
    "    # ---- Embedding ----\n",
    "    if hasattr(model, \"embedding\"):\n",
    "        embed_dim = model.embedding.embedding_dim\n",
    "    elif hasattr(model, \"emb\"):\n",
    "        embed_dim = model.emb.embedding_dim\n",
    "    else:\n",
    "        embed_dim = None  # e.g. transformer with external embeddings\n",
    "\n",
    "    # ---- Learning rate ----\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # ---- Model type detection ----\n",
    "    if hasattr(model, \"lstm\"):\n",
    "        hidden_dim = model.lstm.hidden_size\n",
    "        layers = model.lstm.num_layers\n",
    "        model_type = \"BiLSTM\"\n",
    "\n",
    "    elif hasattr(model, \"rnn\"):\n",
    "        hidden_dim = model.rnn.hidden_size\n",
    "        layers = model.rnn.num_layers\n",
    "        model_type = \"BiRNN\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported model: expected attribute 'lstm' or 'rnn'\"\n",
    "        )\n",
    "\n",
    "    return model_type, hidden_dim, embed_dim, layers, lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa228b25",
   "metadata": {
    "papermill": {
     "duration": 0.008996,
     "end_time": "2025-12-14T10:49:07.908319",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.899323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1daa9118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:07.928004Z",
     "iopub.status.busy": "2025-12-14T10:49:07.927672Z",
     "iopub.status.idle": "2025-12-14T10:49:08.053784Z",
     "shell.execute_reply": "2025-12-14T10:49:08.052999Z"
    },
    "papermill": {
     "duration": 0.138673,
     "end_time": "2025-12-14T10:49:08.056127",
     "exception": false,
     "start_time": "2025-12-14T10:49:07.917454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(aa2id) + 1\n",
    "\n",
    "birnn = BiRNN(vocab_size)\n",
    "bilstm = BiLSTM(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b46f8b",
   "metadata": {
    "papermill": {
     "duration": 0.008686,
     "end_time": "2025-12-14T10:49:08.074010",
     "exception": false,
     "start_time": "2025-12-14T10:49:08.065324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-RNN & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8a6ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:49:08.094213Z",
     "iopub.status.busy": "2025-12-14T10:49:08.093347Z",
     "iopub.status.idle": "2025-12-14T11:04:39.091527Z",
     "shell.execute_reply": "2025-12-14T11:04:39.090513Z"
    },
    "papermill": {
     "duration": 931.010753,
     "end_time": "2025-12-14T11:04:39.093658",
     "exception": false,
     "start_time": "2025-12-14T10:49:08.082905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiRNN...\n",
      "Run name: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "* Trackio project initialized: 25-t3-nppe2\n",
      "* Trackio metrics will be synced to Hugging Face Dataset: bytescode/dlgenai-nppe-dataset\n",
      "* Found existing space: https://huggingface.co/spaces/bytescode/dlgenai-nppe\n",
      "* View dashboard by going to: https://bytescode-dlgenai-nppe.hf.space/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bytescode-dlgenai-nppe.hf.space/\" width=\"100%\" height=\"1000px\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Created new run: sst-BiRNN-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiRNN-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11: 100%|██████████| 1634/1634 [01:22<00:00, 19.79it/s, loss8=1.1461, loss3=0.6653, total=2.3844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.2778 | F1-3=0.6647 | HM=0.3918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11: 100%|██████████| 1634/1634 [01:23<00:00, 19.64it/s, loss8=0.9433, loss3=0.6193, total=2.0342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.2839 | F1-3=0.6804 | HM=0.4006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11: 100%|██████████| 1634/1634 [01:23<00:00, 19.58it/s, loss8=1.2660, loss3=0.7095, total=2.6086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.2892 | F1-3=0.6815 | HM=0.4061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11: 100%|██████████| 1634/1634 [01:22<00:00, 19.84it/s, loss8=1.2035, loss3=0.7201, total=2.5254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.3003 | F1-3=0.6810 | HM=0.4168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11: 100%|██████████| 1634/1634 [01:22<00:00, 19.71it/s, loss8=1.2315, loss3=0.7002, total=2.5474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3103 | F1-3=0.6886 | HM=0.4278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11: 100%|██████████| 1634/1634 [01:22<00:00, 19.74it/s, loss8=1.1682, loss3=0.6881, total=2.4404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.3020 | F1-3=0.6634 | HM=0.4150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.19it/s, loss8=1.3494, loss3=0.9034, total=2.9274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.3084 | F1-3=0.6891 | HM=0.4261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.22it/s, loss8=1.2554, loss3=0.6890, total=2.5722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3059 | F1-3=0.6804 | HM=0.4221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.17it/s, loss8=1.1580, loss3=0.7198, total=2.4568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3129 | F1-3=0.6945 | HM=0.4314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11: 100%|██████████| 1634/1634 [01:20<00:00, 20.26it/s, loss8=1.1097, loss3=0.6609, total=2.3255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3091 | F1-3=0.6967 | HM=0.4282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11: 100%|██████████| 1634/1634 [01:21<00:00, 20.06it/s, loss8=1.0728, loss3=0.5786, total=2.1878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3105 | F1-3=0.6960 | HM=0.4294\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiRNN-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiRNN:\n",
    "    print(\"Training BiRNN...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(birnn.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 11\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        birnn, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "\n",
    "    birnn_model = train_model(model=birnn, optimizer=optimizer, criterion=criterion, \n",
    "                              scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(birnn_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping BiRNN training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af17eb",
   "metadata": {
    "papermill": {
     "duration": 1.076759,
     "end_time": "2025-12-14T11:04:41.233640",
     "exception": false,
     "start_time": "2025-12-14T11:04:40.156881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Bi-LSTM & uploading to kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f73b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:04:43.287377Z",
     "iopub.status.busy": "2025-12-14T11:04:43.286715Z",
     "iopub.status.idle": "2025-12-14T11:33:25.694870Z",
     "shell.execute_reply": "2025-12-14T11:33:25.693745Z"
    },
    "papermill": {
     "duration": 1723.410377,
     "end_time": "2025-12-14T11:33:25.697026",
     "exception": false,
     "start_time": "2025-12-14T11:04:42.286649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM...\n",
      "Run name: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "* Created new run: sst-BiLSTM-h256_e128_l2_lr0.0003\n",
      "[TrackIO] Run initialized → sst-BiLSTM-h256_e128_l2_lr0.0003 (Group: baseline_models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/17: 100%|██████████| 1634/1634 [01:37<00:00, 16.80it/s, loss8=1.2448, loss3=0.7232, total=2.5904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation | F1-8=0.2803 | F1-3=0.6757 | HM=0.3962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/17: 100%|██████████| 1634/1634 [01:39<00:00, 16.44it/s, loss8=1.2321, loss3=0.7955, total=2.6436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation | F1-8=0.2911 | F1-3=0.6860 | HM=0.4087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.56it/s, loss8=0.8959, loss3=0.5363, total=1.8801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation | F1-8=0.2986 | F1-3=0.6894 | HM=0.4167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.57it/s, loss8=1.1172, loss3=0.6510, total=2.3268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation | F1-8=0.3073 | F1-3=0.6857 | HM=0.4244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.59it/s, loss8=1.0691, loss3=0.6264, total=2.2301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation | F1-8=0.3102 | F1-3=0.7003 | HM=0.4300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.65it/s, loss8=1.1329, loss3=0.6703, total=2.3697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation | F1-8=0.3208 | F1-3=0.6948 | HM=0.4389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.59it/s, loss8=0.9898, loss3=0.5461, total=2.0308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation | F1-8=0.3186 | F1-3=0.6998 | HM=0.4379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.54it/s, loss8=1.0945, loss3=0.5878, total=2.2294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation | F1-8=0.3133 | F1-3=0.6994 | HM=0.4327\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.60it/s, loss8=1.1691, loss3=0.5746, total=2.3282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation | F1-8=0.3162 | F1-3=0.6978 | HM=0.4352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/17: 100%|██████████| 1634/1634 [01:39<00:00, 16.50it/s, loss8=1.1284, loss3=0.6487, total=2.3413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation | F1-8=0.3274 | F1-3=0.7032 | HM=0.4467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.53it/s, loss8=0.8673, loss3=0.5052, total=1.8062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation | F1-8=0.3267 | F1-3=0.7020 | HM=0.4459\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.55it/s, loss8=1.1310, loss3=0.6049, total=2.3014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation | F1-8=0.3267 | F1-3=0.7006 | HM=0.4456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.60it/s, loss8=1.0600, loss3=0.5727, total=2.1627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation | F1-8=0.3244 | F1-3=0.6974 | HM=0.4428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/17: 100%|██████████| 1634/1634 [01:39<00:00, 16.49it/s, loss8=0.6405, loss3=0.3377, total=1.2984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation | F1-8=0.3277 | F1-3=0.6979 | HM=0.4459\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.65it/s, loss8=1.0594, loss3=0.5818, total=2.1709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation | F1-8=0.3271 | F1-3=0.6967 | HM=0.4451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.60it/s, loss8=0.5991, loss3=0.3716, total=1.2702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation | F1-8=0.3279 | F1-3=0.6963 | HM=0.4458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/17: 100%|██████████| 1634/1634 [01:38<00:00, 16.55it/s, loss8=0.9583, loss3=0.5477, total=1.9852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation | F1-8=0.3256 | F1-3=0.6957 | HM=0.4436\n",
      "\n",
      "* Run finished. Uploading logs to Trackio (please wait...)\n",
      "Training finished & logged to TrackIO.\n",
      "\n",
      "Saved model weights: sst-BiLSTM-h256_e128_l2_lr0.0003.pth\n"
     ]
    }
   ],
   "source": [
    "if canTrain and canTrainBiLSTM:\n",
    "    print(\"Training BiLSTM...\\n\", end=\"\")\n",
    "\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.AdamW(bilstm.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    epochs = 17\n",
    "\n",
    "    model_type, hidden_dim, embed_dim, layers, _ = get_model_params(\n",
    "        bilstm, optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    MODEL = f\"sst-{model_type}\"\n",
    "    VARIATION = f\"h{hidden_dim}_e{embed_dim}_l{layers}_lr{lr}\"\n",
    "    name = f\"{MODEL}-{VARIATION}\"\n",
    "\n",
    "    print(\"Run name:\", name)\n",
    "\n",
    "    trackioInit(\n",
    "        run_name=name,\n",
    "        group=\"baseline_models\",\n",
    "        optimizer=optimizer,\n",
    "        batch_size=trainLoader.batch_size,\n",
    "        extra_config={\n",
    "            \"epochs\": epochs,\n",
    "            \"model_type\": model_type,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"layers\": layers,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    )\n",
    "    model = bilstm\n",
    "    bilstm_model = train_model(model=bilstm, optimizer=optimizer, criterion=criterion,\n",
    "        scheduler=scheduler, epochs=epochs, w8=1.5, w3=1.0)\n",
    "\n",
    "    save_path = f\"{name}.pth\"\n",
    "    torch.save(bilstm_model.state_dict(), save_path)\n",
    "    print(\"Saved model weights:\", save_path)\n",
    "\n",
    "    handle = f\"{KAGGLE_USERNAME}/{MODEL}/{FRAMEWORK}/{VARIATION}\"\n",
    "    #kagglehub.model_upload(handle, save_path, version_notes=f\"{MODEL} trained version : {VARIATION}\")\n",
    "    #print(f\"Uploaded model to Kaggle Hub: {handle}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping training — going for submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d75549",
   "metadata": {
    "papermill": {
     "duration": 2.865957,
     "end_time": "2025-12-14T11:33:31.316150",
     "exception": false,
     "start_time": "2025-12-14T11:33:28.450193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d53064",
   "metadata": {
    "papermill": {
     "duration": 2.738383,
     "end_time": "2025-12-14T11:33:36.894550",
     "exception": false,
     "start_time": "2025-12-14T11:33:34.156167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b913de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:33:42.511982Z",
     "iopub.status.busy": "2025-12-14T11:33:42.511070Z",
     "iopub.status.idle": "2025-12-14T11:33:47.370726Z",
     "shell.execute_reply": "2025-12-14T11:33:47.369334Z"
    },
    "papermill": {
     "duration": 7.744989,
     "end_time": "2025-12-14T11:33:47.372788",
     "exception": false,
     "start_time": "2025-12-14T11:33:39.627799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL COMPARISON ===\n",
      "\n",
      "BiRNN  → F1-8=0.3105 | F1-3=0.6960 | HM=0.4294\n",
      "BiLSTM → F1-8=0.3256 | F1-3=0.6957 | HM=0.4436\n",
      "\n",
      ">>> BiLSTM is better overall.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MODEL COMPARISON ===\\n\")\n",
    "\n",
    "birnn_f18, birnn_f13, birnn_hm = evaluate(birnn_model, valLoader)\n",
    "bilstm_f18, bilstm_f13, bilstm_hm = evaluate(bilstm_model, valLoader)\n",
    "\n",
    "print(f\"BiRNN  → F1-8={birnn_f18:.4f} | F1-3={birnn_f13:.4f} | HM={birnn_hm:.4f}\")\n",
    "print(f\"BiLSTM → F1-8={bilstm_f18:.4f} | F1-3={bilstm_f13:.4f} | HM={bilstm_hm:.4f}\")\n",
    "\n",
    "if bilstm_hm > birnn_hm:\n",
    "    print(\"\\n>>> BiLSTM is better overall.\")\n",
    "else:\n",
    "    print(\"\\n>>> BiRNN is better overall.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ee9a6",
   "metadata": {
    "papermill": {
     "duration": 2.72902,
     "end_time": "2025-12-14T11:33:52.923862",
     "exception": false,
     "start_time": "2025-12-14T11:33:50.194842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selection Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a84c9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:33:58.423754Z",
     "iopub.status.busy": "2025-12-14T11:33:58.423364Z",
     "iopub.status.idle": "2025-12-14T11:33:58.428742Z",
     "shell.execute_reply": "2025-12-14T11:33:58.427835Z"
    },
    "papermill": {
     "duration": 2.758013,
     "end_time": "2025-12-14T11:33:58.430861",
     "exception": false,
     "start_time": "2025-12-14T11:33:55.672848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Best model selected: BiLSTM\n"
     ]
    }
   ],
   "source": [
    "if bilstm_hm > birnn_hm:\n",
    "    best_model = bilstm_model\n",
    "    best_name = \"BiLSTM\"\n",
    "else:\n",
    "    best_model = birnn_model\n",
    "    best_name = \"BiRNN\"\n",
    "\n",
    "print(f\"\\n>>> Best model selected: {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52342fe7",
   "metadata": {
    "papermill": {
     "duration": 2.696874,
     "end_time": "2025-12-14T11:34:03.942542",
     "exception": false,
     "start_time": "2025-12-14T11:34:01.245668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35fe8f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:34:09.411074Z",
     "iopub.status.busy": "2025-12-14T11:34:09.410704Z",
     "iopub.status.idle": "2025-12-14T11:34:09.418214Z",
     "shell.execute_reply": "2025-12-14T11:34:09.417262Z"
    },
    "papermill": {
     "duration": 2.786927,
     "end_time": "2025-12-14T11:34:09.420134",
     "exception": false,
     "start_time": "2025-12-14T11:34:06.633207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    model.eval()\n",
    "\n",
    "    seqs8, seqs3 = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq in df[\"seq\"]:\n",
    "            # Clean sequence (important!)\n",
    "            seq = re.sub(r\"[BOUZX*]\", \"X\", seq)\n",
    "\n",
    "            # Encode\n",
    "            x = torch.tensor(\n",
    "                [aa2id.get(a, aa2id[\"X\"]) for a in seq],\n",
    "                dtype=torch.long\n",
    "            ).unsqueeze(0).to(device)\n",
    "\n",
    "            lengths = torch.tensor([len(seq)], dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward\n",
    "            p8, p3 = model(x, lengths)\n",
    "\n",
    "            pred8 = p8.argmax(dim=-1)[0].tolist()\n",
    "            pred3 = p3.argmax(dim=-1)[0].tolist()\n",
    "\n",
    "            # Decode → characters\n",
    "            s8 = \"\".join(id2sst8[i] for i in pred8)\n",
    "            s3 = \"\".join(id2sst3[i] for i in pred3)\n",
    "\n",
    "            seqs8.append(s8)\n",
    "            seqs3.append(s3)\n",
    "\n",
    "    return seqs8, seqs3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132c738",
   "metadata": {
    "papermill": {
     "duration": 2.685523,
     "end_time": "2025-12-14T11:34:14.936640",
     "exception": false,
     "start_time": "2025-12-14T11:34:12.251117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict (sst8 & sst3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8692adae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:34:20.374436Z",
     "iopub.status.busy": "2025-12-14T11:34:20.373463Z",
     "iopub.status.idle": "2025-12-14T11:34:40.606898Z",
     "shell.execute_reply": "2025-12-14T11:34:40.605865Z"
    },
    "papermill": {
     "duration": 22.994238,
     "end_time": "2025-12-14T11:34:40.609162",
     "exception": false,
     "start_time": "2025-12-14T11:34:17.614924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_s8, test_s3 = predict(best_model, testDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2cc02",
   "metadata": {
    "papermill": {
     "duration": 2.674588,
     "end_time": "2025-12-14T11:34:46.109623",
     "exception": false,
     "start_time": "2025-12-14T11:34:43.435035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b408476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:34:51.628777Z",
     "iopub.status.busy": "2025-12-14T11:34:51.628414Z",
     "iopub.status.idle": "2025-12-14T11:34:51.674460Z",
     "shell.execute_reply": "2025-12-14T11:34:51.673456Z"
    },
    "papermill": {
     "duration": 2.875522,
     "end_time": "2025-12-14T11:34:51.676369",
     "exception": false,
     "start_time": "2025-12-14T11:34:48.800847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCCTTHHHHHHHHHHHHHHHHHHCSEEEEEECCCTCCEEEEEEECT...</td>\n",
       "      <td>CCCCCHHHHHHHHHHHHHHHHHHCCEEEEEECCCCCCEEEEEECCC...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CCCCCCCCCEEEEEEEECSTTCEEEEEETTTCEEEEECCCCCCCGG...</td>\n",
       "      <td>CCCCCCCCCCEEEEEEECCCCCEEEEEECCCCEEECCCCCCCCCHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CTHHHHHHHHHHHHHHHHHTTHHHHHHHHHHHHHHCCTTHHHHHHH...</td>\n",
       "      <td>CCHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHHHHCCCHHHHHHHH...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CCCTTHHHHHHHHHHHHHHHHHHHHHHHHCEEEEETTHHHHHCCHH...</td>\n",
       "      <td>CCCCCHHHHHHHHHHHHHHHHHHHHHHHHCCEEECCCHHHHHCCHH...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CEEEEEEECCCTTHHHHHHHHHHHHHHEEEEECCTTTCEEEETSEE...</td>\n",
       "      <td>CEEEEEECCCCCCHHHHHHHHHHHHHHEEEEEECCCCEEEEECCCE...</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               sst8  \\\n",
       "0   0  CCCTTHHHHHHHHHHHHHHHHHHCSEEEEEECCCTCCEEEEEEECT...   \n",
       "1   1  CCCCCCCCCEEEEEEEECSTTCEEEEEETTTCEEEEECCCCCCCGG...   \n",
       "2   2  CTHHHHHHHHHHHHHHHHHTTHHHHHHHHHHHHHHCCTTHHHHHHH...   \n",
       "3   3  CCCTTHHHHHHHHHHHHHHHHHHHHHHHHCEEEEETTHHHHHCCHH...   \n",
       "4   4  CEEEEEEECCCTTHHHHHHHHHHHHHHEEEEECCTTTCEEEETSEE...   \n",
       "\n",
       "                                                sst3    Usage  \n",
       "0  CCCCCHHHHHHHHHHHHHHHHHHCCEEEEEECCCCCCEEEEEECCC...  Private  \n",
       "1  CCCCCCCCCCEEEEEEECCCCCEEEEEECCCCEEECCCCCCCCCHH...  Private  \n",
       "2  CCHHHHHHHHHHHHHHHHHCCHHHHHHHHHHHHHHCCCHHHHHHHH...   Public  \n",
       "3  CCCCCHHHHHHHHHHHHHHHHHHHHHHHHCCEEECCCHHHHHCCHH...  Private  \n",
       "4  CEEEEEECCCCCCHHHHHHHHHHHHHHEEEEEECCCCEEEEECCCE...  Private  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sampleDf.copy()\n",
    "\n",
    "submission[\"sst8\"] = test_s8\n",
    "submission[\"sst3\"] = test_s3\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv\\n\")\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14858151,
     "sourceId": 125543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2841.316548,
   "end_time": "2025-12-14T11:34:58.112271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T10:47:36.795723",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
